{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to test the performance of a QIF framework for non-Markovian, covariance stationary process using non-linear quantised measurements.\n",
    "\n",
    "#### TRUE DYNAMICS\n",
    "\n",
    "We will use AKF coefficients for the true test cases defined in the linear regime.\n",
    "- true_rk_quant = 0.001^2\n",
    "- QKF is fed AKF (optimal) sigma\n",
    "- OKF is tuned for a new R"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PREAMBLE COMMANDS ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../../')\n",
    "\n",
    "#### Local KF Tuning Helpers ####\n",
    "from data_tools.data_risk_analysis import build_risk_dict, riskmapdata\n",
    "from data_tools.load_raw_cluster_data import LoadExperiment\n",
    "\n",
    "#### Local QIF Filter and Helper Functions ####\n",
    "from qif.qif import qif as qif\n",
    "from qif.common import generate_AR, noisy_z, projected_msmt, qkf_state_err, normalise\n",
    "from ls.common import doLSF_forecast\n",
    "\n",
    "#### Local Plotting Tools ####\n",
    "from plot_tools.fig_preamble import *\n",
    "from plot_tools.plot_figstyle_sheet import STYLEDICT, COLOURDICT\n",
    "from plot_tools.plot_helper_funcs import cm2inch\n",
    "\n",
    "#### Matplotlib & Numpy ####\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "mpl.rc('font', size=8)\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import ScalarFormatter, FormatStrFormatter\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "\n",
    "#### Global Plotting and Saving Commands ####\n",
    "\n",
    "############ Saving Commands #########\n",
    "\n",
    "ver=0\n",
    "datapath = '../../DATA_v'+str(ver)+'_/' #v'+str(ver)+'/DATA_v'+str(ver)+'/'\n",
    "savefig = './analysis_figs'\n",
    "figname = 'tc_19_linear_regime_2_'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### LOW Q REGIME - AR(2) PROCESS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to satisfy the following constraints \n",
    "\n",
    "For stationarity:\n",
    "    (a) ph1 + ph2 < 1\n",
    "    (b) ph1 - ph2 < 1\n",
    "    (c) phi2| < 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ######## Covariance Stationary, MS Ergoic AR(2) Process#######\n",
    "# # Stationary ARMA: http://matthieustigler.github.io/Lectures/Lect2ARMA.pdf\n",
    "\n",
    "# ar1 = -0.02# \n",
    "# ar2 = +0.968\n",
    "# q_regime.append(np.asarray([ar1, ar2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### HIGH Q REGIME - AR(q) PROCESS USING LEARNED LSF WEIGHTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We want to load a high order AR(q) model where we know that underlyign truth is stationary.\n",
    "\n",
    "test_case = 19\n",
    "variation_scan = [9, 1, 5, 8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Noise Parameters\n",
    "\n",
    "In order to generate our true process, we will take tuned parameters from the linear AKF optimisation procedure. We retain an additional measurement noise term - which is white noise added prior to quantisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "######## Msmt Noise Strength Prior to Quantisation\n",
    "true_rk_quant = 0.001**2\n",
    "####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up of Algorithm Parameters (QKF, LSF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###### Number of data points and initial points to exclude (burnin) #####\n",
    "num = 2100\n",
    "burn_in = 0\n",
    "\n",
    "###### AR Process Initialisation #####\n",
    "# we need phases to accumulate from 0 to pi. So our process is no longer mean zero.\n",
    "mean_noise = 0.5*np.pi\n",
    "\n",
    "###### Bayes Risk Runs ######\n",
    "runs = 50\n",
    "num_rand_r = 75\n",
    "space_size = np.arange(-6, 6) # machine precision + expect R to be higher than in the linear regime\n",
    "\n",
    "########### LSF ##############\n",
    "pick_alpha=0.1\n",
    "n_predict = 100\n",
    "n_testbefore = 50\n",
    "n_train=num-n_predict\n",
    "num_of_iterGD = 50\n",
    "\n",
    "########### KF ##############\n",
    "p0init = 1000 # set same as AKF /LSF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.signal import periodogram\n",
    "\n",
    "def autocorr(x):\n",
    "    result = np.correlate(x, x, mode='full')\n",
    "    return result[result.size/2:]\n",
    "\n",
    "def func_x0(space_size):\n",
    "    '''\n",
    "    Returns random dim =2 arrays from a parameter space defined by space_size\n",
    "    [Helper function for Bayes Risk mapping]\n",
    "    '''\n",
    "    maxindex = space_size.shape[0]-1\n",
    "    ind = int(np.random.uniform(low=0, high=maxindex))\n",
    "    exponent = space_size[ind]\n",
    "    return np.random.uniform(0,1)*(10.0**exponent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  QIF BR MAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for idx_q_regime in xrange(len(variation_scan)):\n",
    "    \n",
    "    experiment = LoadExperiment(test_case, variation_scan[idx_q_regime], \n",
    "                                LKFFB_load ='No',\n",
    "                                LSF_load='No',\n",
    "                                AKF_load='Yes', \n",
    "                                AKF_path=datapath,\n",
    "                                GPRP_load='No')\n",
    "    \n",
    "    z_states_errs_= np.zeros((num_rand_r, runs, num))\n",
    "    norm_z_states_= np.zeros((num_rand_r, runs, num))\n",
    "    macro_truth = np.zeros((num_rand_r, runs, num))\n",
    "    \n",
    "    # We extract tuned parameters from linear regimeto specify the dynamical model\n",
    "\n",
    "    riskmapexpt = build_risk_dict(experiment)\n",
    "\n",
    "    tuned_sigma, tuned_R = riskmapdata(riskmapexpt['AKF'][0], \n",
    "                                   riskmapexpt['AKF'][2], \n",
    "                                   riskmapexpt['AKF'][1],\n",
    "                                   maxforecaststps=50,\n",
    "                                   maxstateeststps=50)[0:2]\n",
    "\n",
    "    print(\"Optimal KF pair from linear regime\", tuned_sigma[0], tuned_R[0])\n",
    "    \n",
    "    ######### Tune Kalman R ############\n",
    "    \n",
    "    random_hyperparams_list = np.zeros((num_rand_r, 2))\n",
    "    rand_r=np.zeros(num_rand_r)\n",
    "    \n",
    "    for idx_r in xrange(num_rand_r):\n",
    "        \n",
    "        rand_r[idx_r] = func_x0(space_size)\n",
    "        \n",
    "        # We make a truth bank of all f_n generated in the linear msmt regime\n",
    "        shape = experiment.AKF_macro_truth.shape\n",
    "        truth_bank = experiment.AKF_macro_truth.reshape(shape[0]*shape[1], shape[2]) # collapsed\n",
    "\n",
    "        # We extract the the AR(q) regime of coefficients\n",
    "        AKF_weights = experiment.AKF_weights\n",
    "        order = AKF_weights.shape[0]\n",
    "        n_start_at=n_train - order + 1\n",
    "\n",
    "        # We store placeholders for analysis\n",
    "        x_true_dynamics = np.zeros((runs, order, num))\n",
    "        gain_true_dynamics = np.zeros((runs, order, num))\n",
    "        truths_ = np.zeros((runs, num))\n",
    "        err_true_dynamics = np.zeros((runs, num))\n",
    "        \n",
    "        random_hyperparams_list[idx_r, 0] = tuned_sigma[0]*func_x0(np.arange(-2, 3)) # tune sigma around prev optimal\n",
    "        random_hyperparams_list[idx_r, 1] = rand_r[idx_r] # tune R\n",
    "\n",
    "\n",
    "        ######### Make an ensemble of QIF experiments for same trial of R ############\n",
    "\n",
    "        for idx_run in xrange(runs):\n",
    "\n",
    "            # Pick truth for one run\n",
    "            pickone = int(np.random.uniform(low=0, high = int(truth_bank.shape[0]-1)))\n",
    "            true_x = truth_bank[pickone, :] + mean_noise \n",
    "            truths_[idx_run, :] = true_x # this is mean 0.5 pi \n",
    "\n",
    "            # Our data set is a noisy f_n sequence which incurs a non linear msmt action + AGWN prior to quantisation \n",
    "            f_n_dataset = true_x + experiment.AKF_msmt_noise_variance*np.random.standard_normal(true_x.shape)\n",
    "            noisy_z_ = noisy_z( f_n_dataset, true_rk_quant) # z is mean zero\n",
    "\n",
    "            # Generate single shot outcomes dataset\n",
    "            y_signal = projected_msmt(noisy_z_)\n",
    "\n",
    "            # Run QIF using AKF Dynamics \n",
    "            predictions, W, x_hat, P_hat, err_true_dynamics[idx_run, :] = qif('AKFdynamics', y_signal, \n",
    "                                                                              AKF_weights, \n",
    "                                                                              tuned_sigma[0], rand_r[idx_r],\n",
    "                                                                              n_train=n_train, \n",
    "                                                                              n_testbefore=n_predict, \n",
    "                                                                              n_predict=n_predict, \n",
    "                                                                              p0=p0init, skip_msmts=1,  save='No')\n",
    "            # Store run for this experiment\n",
    "            x_true_dynamics[idx_run, :, :] = x_hat[:,0,:]\n",
    "            gain_true_dynamics[idx_run, :, :] = W[:,0,:]\n",
    "\n",
    "\n",
    "        ######### Calculate Bayes Risk with respect to z for each variation, R ############\n",
    "        z_true_dynamics = np.asarray([noisy_z(sequence, 0.) for sequence in x_true_dynamics[:, 0, 0:num]])\n",
    "\n",
    "        ######### Calculate Bayes Risk for predicting mean z = 0.5cos(f_n) == 0  ############\n",
    "        truths_z = np.asarray([noisy_z(sequence, 0.) for sequence in truths_[:, 0:num]])\n",
    "        predict_one = np.mean((truths_z)**2, axis=0)\n",
    "\n",
    "        ######### Normalise Bayes Risk  ############\n",
    "        # ensure this is consistently calculated with linear regime. \n",
    "        z_states_errs_[idx_r, :, :] = qkf_state_err(z_true_dynamics[:, :], truths_z)\n",
    "        norm_z_states_[idx_r, :, :] = z_states_errs_[idx_r, :, :] / predict_one\n",
    "        macro_truth[idx_r, :, :] = truths_z\n",
    "    \n",
    "    ######### Save BR Map for experiment  ############\n",
    "    \n",
    "    filename = 'test_case_'+str(test_case)+'_var_'+str(variation_scan[idx_q_regime])+'BR_QKF_Map.npz'\n",
    "    \n",
    "    np.savez(datapath+filename, \n",
    "             random_hyperparams_list=random_hyperparams_list, \n",
    "             macro_truth=macro_truth, \n",
    "             macro_prediction_errors=z_states_errs_[:,:,n_train-n_testbefore:num],\n",
    "             macro_forecastng_errors=z_states_errs_[:,:,n_train:],\n",
    "             norm_z_states_=norm_z_states_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "case_labels = ['(a)', '(b)', '(c)', '(d)']\n",
    "ALGO_LIST = ['QKF'] #['LSF', 'AKF', 'LKFFB']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Fig Setup\n",
    "nrows = 1\n",
    "ncols = 4\n",
    "\n",
    "\n",
    "gs = gridspec.GridSpec(nrows, ncols,\n",
    "                       left=0.08, right=0.99, \n",
    "                       top=0.9, bottom=0.15, \n",
    "                       wspace=0.04, hspace=0.65)\n",
    "\n",
    "fig = plt.figure(figsize=(cm2inch(20.), cm2inch(4.5)), dpi=my_dpi)\n",
    "dumpfig = plt.figure(figsize=(1, 1))\n",
    "dumpax = dumpfig.add_subplot(111)\n",
    "\n",
    "# Plot loss maps\n",
    "\n",
    "for idx_c in xrange(len(variation_scan)):\n",
    "    \n",
    "    vars()['ax'+str(idx_c)+'_mean']  = fig.add_subplot(gs[0, idx_c])\n",
    "    dumpax, vars()['ax'+str(idx_c)+'_mean'] = pnm(dumpax, vars()['ax'+str(idx_c)+'_mean'],  ALGO_LIST, \n",
    "                                           test_case, variation_scan[idx_c], \n",
    "                                           datapath,\n",
    "                                           fstep=50, sstep=50, lowloss=20, \n",
    "                                           ylim = [-3, 3], yscale='log')\n",
    "    \n",
    "\n",
    "    vars()['ax'+str(idx_c)+'_mean'].text(0.4, 1.07, case_labels[idx_c], transform=vars()['ax'+str(idx_c)+'_mean'].transAxes)\n",
    "    if idx_c !=0:\n",
    "        vars()['ax'+str(idx_c)+'_mean'].set(title='', ylabel='', yticklabels=[])\n",
    "    if idx_c !=1:\n",
    "        vars()['ax'+str(idx_c)+'_mean'].set(xlabel='')\n",
    "        \n",
    "    vars()['ax'+str(idx_c)+'_mean'] = set_font_sizes(vars()['ax'+str(idx_c)+'_mean'], fsize, Fsize)\n",
    "\n",
    "#fig.savefig(savefig+figname+'.svg', format='svg')\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "## Fig Setup\n",
    "nrows = 2\n",
    "ncols = 4\n",
    "THRES=15\n",
    "case_thres = ['10', '10', '10', '30']\n",
    "case_thres_med_ratio_LKFFB = ['10', '10', '10', '30']\n",
    "case_thres_med_ratio_AKF = ['10', '10', '10', '30']\n",
    "\n",
    "gs = gridspec.GridSpec(nrows, ncols,\n",
    "                       left=0.08, right=0.99, \n",
    "                       top=0.99, bottom=0.15, \n",
    "                       wspace=0.04, hspace=0.04)\n",
    "\n",
    "fig = plt.figure(figsize=(cm2inch(20.), cm2inch(10.)), dpi=my_dpi)\n",
    "dumpfig = plt.figure(figsize=(0.1, 0.1))\n",
    "dumpax = dumpfig.add_subplot(111)\n",
    "\n",
    "for idx_c in xrange(len(variation_scan)):\n",
    "    \n",
    "    vars()['ax'+str(idx_c)+'_1']  = fig.add_subplot(gs[0, idx_c])\n",
    "    vars()['ax'+str(idx_c)+'_2']  = fig.add_subplot(gs[1, idx_c])\n",
    "    \n",
    "    vars()['ax'+str(idx_c)+'_1'], vars()['ax'+str(idx_c)+'_2'] = plot_risk_map_2(vars()['ax'+str(idx_c)+'_1'], \n",
    "                                                                                 ALGO_LIST, \n",
    "                      test_case, variation_scan[idx_c], datapath, lowloss=THRES,\n",
    "                      figax2=vars()['ax'+str(idx_c)+'_2'], xlim=[-22, 6], ylim = [-3, 2])\n",
    "    \n",
    "    vars()['ax'+str(idx_c)+'_1'].text(0.4, 1.07, case_labels[idx_c], fontsize=Fsize, \n",
    "                                      #+r': $L^*<$ %s'%(case_thres[idx_c]), \n",
    "                                      transform=vars()['ax'+str(idx_c)+'_1'].transAxes)\n",
    "    if idx_c !=0:\n",
    "        vars()['ax'+str(idx_c)+'_1'].set(title='', xlabel='', xticklabels=[], ylabel='', yticklabels=[])\n",
    "        vars()['ax'+str(idx_c)+'_2'].set(title='', xlabel='', ylabel='', yticklabels=[])\n",
    "    vars()['ax'+str(0)+'_1'].set(title='', xlabel='', xticklabels=[])\n",
    "    vars()['ax'+str(0)+'_2'].set(title='', ylabel='')\n",
    "    \n",
    "    for ax in [vars()['ax'+str(idx_c)+'_1'], vars()['ax'+str(idx_c)+'_2']]:\n",
    "        ax = set_font_sizes(ax, fsize, Fsize)\n",
    "    \n",
    "    \n",
    "#fig.savefig(savefig+figname+'_B.svg', format='svg')\n",
    "\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
