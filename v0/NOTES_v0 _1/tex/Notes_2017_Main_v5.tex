The domain of classical predictive estimation in engineering and Bayesian analysis harnesses a rich collection of computational techniques to extract correlation information from observed data records. These techniques have found diverse applications in state tracking, pattern recognition, short-range predictive control and autonomous learning [REFS].  In the context of developing control strategies for quantum bits (qubits) in realistic operating environments, we observe that measurements on single qubits encode correlation information associated with environmental decoherence processes commonly encountered in the laboratory. We seek suitably modified control engineering and machine learning frameworks to learn noise correlations encoded in  measurement records and enable robust predictive control of qubit state dynamics in real time.   
\\
\\
Meaningful predictive control of qubits in our context means that we seek to maximise the forward prediction horizon beyond the observed data record. We perform  a sequence of measurements on single qubits where the measurement action resets the quantum state of the qubit i.e. a projective measurement. A maximal forward prediction horizon beyond the data record enables future control interventions while reducing the need for projective measurements, for example, by interleaving periods of data collection with periods of unsupervised control.  Increasing the forward prediction horizon is contingent on enabling effective state tracking and measurement noise filtering capabilites through an appropriate choice of algorithm. The first demonstration of predictive control using `batch' machine learning algorithms was conducted in  \cite{mavadia2017}.
\\
\\
In this paper, we seek model robust techniques to track arbitrary environmental dephasing to enable predictive control of single qubits using projective measurements. We test the accuracy of our tracking mechanisms and we use frameworks which allow additional white noise filtering. We assess algorithmic predictive performance for maximising the forward prediction horizon relative to predicting the mean of the noise process. We consider predictive performance of algorithms in pathological regimes where learning is imperfect. 
\\
\\
In adapting classical techniques for predictive control in our physical setting, we face several key challenges. Firstly, we wish to track a stochastic qubit dynamics subject to arbitrary, non Markovian dephasing processes. This means that we lack a theoretical dynamical model for propagating qubit state estimates through time and many learning and predictive estimation frameworks operate under a Markov assumption. Secondly, single qubit measurements represent a non-linear, quantised measurement action.  Many classical techniques are optimal for linear filtering and significant complexity is introduced in the regime of non-linear filtering with quantised measurement outcomes. 
\\
\\
In what follows, we present our physical setting in X. We provide an overview of predictive methodologies in Y, and we specify algorithms under consideration in this paper. In Z, we present optimisation procedures for tuning algorithms. Predictive performance of algorithms is compared through results from numerical investigations in J. 


\section{Physical Setting}  
\label{sec:main:1}
We consider a freely evolving single qubit under environmental dephasing. The effect of an environmental dephasing process manifests as time-dependent stochastic detuning, $\delta \omega (t)$, between the qubit frequency and the master clock:
\begin{align}
\op{H}_I & = \frac{\hbar}{2}\delta \omega (t) \p{z}
\end{align}
This detuning is an experimentally measurable quantity in a Ramsey experiment.
\\
\\
We may define the statistical likelihood for observing a qubit state, $d$, given true dephasing noise, $\state$, using Born's rule \cite{ferrie2013}. Denoting the Ramsey wait time as $\tau$, we assume that the measurement action over $\tau$ timescales is much faster than the slow time dependence of dephasing,  $\delta \omega(t)$. Hence, we write the probability of obtaining a measurement outcome, $d \in [0,1]$ corresponding to the qubit in the $(\ket{\p{z}-}, \ket{\p{z}+})$ state respectively as:
\begin{align}
P(d_t | \state_t, \tau, t) &= \begin{cases} \cos(\frac{\state(t,\tau)}{2})^2 \quad \text{for $d=1$} \\   \sin(\frac{\state(t,\tau)}{2})^2  \quad \text{for $ d=0$} \end{cases} \label{eqn:main:likelihood}
\end{align}
where  $ \state(t,\tau) \equiv \int_{t}^{t+\tau} \delta \omega(t') dt'$ at time $t$ for short Ramsey times, $\tau$. The notation $P(d_t | \state_t, \tau, t)$ refers to the conditional probability of seeing a measurement $d_t$ given that a stochastic phase, $\state_t$, accumulated over the qubit at $t$ over a Ramsey experiment with wait-time $\tau$. A full derivation of \cref{eqn:main:likelihood} is in Supplementary Information.
\begin{figure}
\caption{Overview}
\includegraphics[scale=0.9]{paper_fig_1}
\label{fig:main:paper_fig_1}
\end{figure} 
\\
\\
We note that the outcome of a Ramsey measurement depends on the accumulated $\state(t,\tau)$ on the qubit. If $\tau$ is fixed by experiment, then the change in the statistics of measured outcomes over a sequence of Ramsey experiments depends solely on the dephasing process.   For $\tau$ is fixed by experiment, and $t = n \Delta t$ for the $n^{th}$ measurement, we use shorthand $\state(t,\tau) \equiv \state_n$, where $n$ indexes time, $t$. 
\\
\\
In the absence of a theoretical model for the qubit state dynamics as governed by $\state$, we impose properties on environmental dephasing that enables us to use classical predictive control methodologies. We assume dephasing (and hence, $\state$) is non Markovian, covariance stationary and mean square ergodic, that is, a single realisation of the process is drawn from a power spectral density of arbitrary but non-Markovian shape, as in \cref{fig:main:paper_fig_1}(a). We further assume that $\state$  is a Gaussian process. 
\\
\\
We summarise in \cref{fig:main:paper_fig_1} (a) that our measurement record discretises any arbitrary continuous time environmental dephasing in equal time-steps $\Delta t$. Consider a Ramsey measurement with fixed $\tau$. If the next measurement is obtained at $t + \Delta t$ for $\Delta t >> \tau$ and under the slow drift assumption, then the measurement outcome likelihood is given by $P(d_n | \state_n, \tau)$. The resulting set $\{d_n\}$ is our measurement record and it  discretises a continuous time $f$ to yield qubit state dynamics governed by $n$ true stochastic phases, $\{\state_n\}$.
\\
\\
Within this physical setting, we consider two different types of measurement records which facilitate prediction but have implications for the computional tracability of a predictive control methodology. In \cref{fig:main:paper_fig_1}(b), a record of $\{ d_n\}$  corressponds to a binary sequence of single shot qubit outcomes. The measurement action of a predictive control algorithm inherits a non linear measurement specfied by \cref{eqn:main:likelihood}. One may pre-process a binary sequence to yield estimates of the stochastic phase, $\{ \hat{\state}_n\}$ and define this to be corrupted by measurement noise, yielding a measurement record $\{ y_n\}$ . In the latter regime, the measurement action is linear for a predictive control methodology, but resources expended to develop $\{ y_n\}$ are beyond the consideration of predictive frameworks.
\\
\\
We briefy discuss several ways in which binary measurements can be pre-processed to yield $\{ \hat{\state}_n\}$. Firstly, one may low-pass (or decimation) filtered a sequence of $\{ d_n\}$ binary outcomes to yield $\hat{P}(d_t | \state_t, \tau, t)$ from which accumulated phase $\{ \hat{\state}_n\}$ can be derived from \cref{eqn:main:likelihood}. A numerical demonstration of decimation filtering is included in Supplementary Information. Secondly, one may perform $M$ runs of the experiment over which $\delta \omega (t)$ is approximately constant under the slow drift assumption. For $M\tau << \Delta t$, we obtain an estimate of  $\state_n$ at $t = \Delta t n$ using a Bayesian scheme or Fourier analysis (CITE). In all cases, pre-processing refers to averaging procedures over $\tau$-like timescales much faster than drift of $\delta \omega (t)$ such that $\{ \hat{\state}_n\}$ is a measurement record and a linear measurement model can be considered. 

% \begin{itemize}
% \item The first section should be “physical setting” which simply describes what’s going to be tracked.  Here you look at time sequences of qubit measurements where the measurements track a dephasing process.  Then you can go into a bit more detail about the manifestation etc.
% \item you can start with a simple Hamiltonian model expressing the role of sigma-z (dephasing) noise, and how it’s manifested as a *measurable* detuning between the qubit and a master clock. You’re relying too heavily on presentaiton from Harrison’s clock paper which is only marginally related to your work.
% \item You need to state what’s being measured - projective msmt of qubit undergoing ramsey and explain or state how that msmt gives an outcome dependent on the accumulated qubit phase during the Ramey expt.  Then ref details in the supplement.
% \item For conditional probabilities, you haven’t defined the relevant symbols. You need to explain this in words.  You audience wont necesarily understand this conditional probability notation.
% \item we assume a slow drift assumption
% \item introduce a high level summary of what is the `truth' being tracked as the truth in this section, adn relegate numeric details in an Appendix
% \end{itemize}

\section{Overview of Predictive Methodologies}  \label{sec:main:2}

We now consider Bayesian frameworks for predictive control. The objective of a  predictive control methdology is to maximise our prediction horizon once experimental data collection ceases. In \cref{fig:main:paper_fig_1}(c), a schematic of algorithmic learning from noisy measurement records are shown for non-linear (linear) Bayesian regime in \cref{fig:main:paper_fig_1}(c) (\cref{fig:main:paper_fig_1}(c-ii)) respectively. Our record consists of $N_T$ noisy $\{ d_n\}$ ($\{ y_n\}$) measurements. Data collection ceases at $n=0$  and we desire algorithmic predictions over $ n \in [0, N_P]$. The fidelity of our algorithm during state estimation and prediction relative to the true state is given as a Bayes Risk, where a zero risk value corresponds to perfect learning. The prediction horizon is the number of time steps for $ n \in [0, N_P]$ during which a predictive algorithm incurs a lower Bayes Risk than simply predicting the mean of the dephasing noise.
\\
\\
We seek to incorporate arbitrary non-Markovian stochastic qubit dynamics in Bayesian learning frameworks. In general, the Bayes update for prior distribution $P(\state_n | \mathcal{D}_{n-1}, \tau)$ based on the the likelihood, $P(d_n | \state_n, \tau)$ for an incoming measurement at $n$: 
\begin{align}
P(\state_n| \mathcal{D}_n, \tau)  \propto P(d_n | \state_n, \tau) P(\state_n | \mathcal{D}_{n-1}, \tau)
\end{align}
The output (aposteriori) distribution, $P(\state_n| \mathcal{D}_n, \tau)$, is the solution to the general, non linear Bayesian inference problem. It is often numerically estimated and subsequently, the mean and the variance of the aposteriori distribution is interepreted as the state estimate and the state variance estimate at $n$. However, we have not yet propagated the state estimates forward in time from $n$ to $n+1$. If $\state$ was Markovian, then it would be straightforward to write a `dynamical model' to enable resampling according to a transition probability, $P(\state_{n+1} | \state_n)$:
\begin{align}
P(\state_{n+1} | \mathcal{D}_{n}, \tau) = \int P(\state_{n+1} | \state_n) P(\state_n | \mathcal{D}_{n}, \tau) d\state_n
\end{align}
Particle filtering and sequential Bayesian adaptive learning protocols for Markov $\state$ have been applied to our problem as $ P(\state_{n+1} | \state_n)$ exists. Relaxing this Markov condition in particle filtering techniques has been the subject of recent research in engineering applications (\cite{wiebe2015bayesian, jacob2016}). Nevertheless, developing a theoretical, non-Markovian transition probability distribution for arbitrary dephasing processes in the context  of our application is beyond the scope of this paper. 
\\
\\
Instead of adopting numerical resampling techniques to solve the general, non-linear Bayesian inference problem, we consider linear Bayesian inference under a Gaussian Process Regression (GPR) framework in \cref{fig:main:paper_fig_1}(d). We define a prior distribution of a family of Gaussian random processes $P(f)$, where `dynamics' are encoded into the correlations relations between random variables in the process via a covariance function (or kernel), $\Sigma_f^{i, j} $.  A general design of $\Sigma_f^{i, j}$ allows one to probe arbitrary stochastic dynamics and optimisation procedures are used to learn the specific dynamical model during training.  Predictive estimation proceeds by defining a joint probability distribution over training data and `test' points at locations where predictions are desired. In a linear Gaussian regime, a predictive probability distribution $P(f^*|y)$ is derived from the joint probability distribution, and the mean of the predictive distribution at test points are interpreted as `state predictions'.
\\
\\
A general, non-linear Bayesian treatment using Bayes Rule can be recast into state space formalism and allows us to draw from powerful classical control engineering techniques. Within the regime of state space Bayesian models, the Kalman Filtering (KF) framework in \cref{fig:main:paper_fig_1}(e) is provably optimal for linear Gaussian regimes but additionally, suitably modified Kalman approaches have demonstrated success in both linear and non-linear tracking and prediction problems in engineering REFS. In this framework, incorporating non-Markovian $\state$ is recast as a design problem whereby a dynamical model, $\Phi$, is a deterministic procedure which `colors' white noise input, $w_n$, yielding a hidden non-Markovian random process, $x$.  Within a Kalman approach, the mean and variance of Gaussian distributions representing the true state, $P(x_{n|n})$ are updated at each time-step accoring to the Kalman gain, $\gamma$, and propagated forwards according to $\Phi$. Prediction ensues when the true state is propagated with zero gain, as in \cref{fig:main:paper_fig_1}(e).  
\\
\\
To follow, we introduce Gaussian Process Regression (GPR) under a linear measurement model. Subsequently, we introduce state space Kalman Filtering (KF) frameworks with both linear and non linear measurment models. For linear regimes, a clear link between KF and GPR is established via the measurement action. 
% \begin{itemize}
% \item Introduce algorithsm, what they do, and how they will be used for predictive estimation. Justify why these algorithms can be used. 
% \item Overview figure on all approaches 
% \item Define the forward prediction horizon. Explain the key concept of how, using different classes of algorithm, you can do prediction and maximise the prediction horizon.
% \item provide a narrative for each algorithm and their equations and explain their relationship to experimentally relevant quantities 
% \end{itemize}

\subsection{GPR}

In GPR, stochastic qubit dynamics are captured by dephasing noise correlations relations between random variables in the Gaussian process, $\state \equiv \{\state_n\}$. Time domain dephasing noise correlations in the measurement record can be learned if one projects data on a distribution of Gaussian processes, $P(\state)$ with an appropriate encoding of their covariance relations via a kernel, $\Sigma_\state^{i,j}$. Sampling this priori distribution, $P(\state)$, yields random realisations of time domain sequences. Hence, the non Markovian dynamics of $f$ are not encoded explicitly but are incorporated through the choice of $\Sigma_\state^{i,j}$. Our choice of a `Periodic kernel' in this paper encodes a covariance function which is theoretically guaranteed to approximate any zero mean covariance stationary process in the mean square limit, namely, by having the same structure as a covariance function for trignometric polynomials.
\\
\\
We formally define the GPR model under a linear measurement regime. Let $\state_n$ be the true random variable belonging to the process $\state$ at time step $n$. Our measurement record is corrupted by additive zero mean white Gaussian noise, $v_n$ with scalar covariance strength $R$, yielding scalar noisy observations $y_n$:
\begin{align}
y_n &= \state_n + v_n \\
v_n & \sim \mathcal{N}(0, R) \quad \forall n
\end{align}
Under linear operations, the distribution of measured outcomes, $y$, is also a Gaussian, with a  mean and variance that depends on $\state$ and $v$: 
\begin{align}
\state & \sim P_\state(\mu_\state,\Sigma_\state ) \\
y & \sim P_y(\mu_y,\Sigma_\state + R ) 
\end{align}
For covariance stationary $\state$, correlation relationships depend solely on the time lag, $v \equiv \Delta t|n_i - n_j|$ between any two random variables at $t_i, t_j$ in $\{ \state_n \}$. An element of the covariance matrix, $\Sigma_\state^{i,j}$, corresponds to one value of lag, $v$, and the correlation for any given $v$  is specified by the covariance function, $R(v)$:
\begin{align}
\Sigma_\state^{i,j} & \equiv R(v_{i,j}) 
\end{align}
The additional notation $\Sigma_\state  \equiv K(N,N)$ is ubitiquous in GPR and we include it to help provide visibility of the time domain set of points over which the covariance function is being calculated.   
\\
\\
Prediction in GPR proceeds by training the GPR model (as described above) over many realisations of dephasing noise processes. Specificially, unknown parameters in the encoding of correlation relations via $R(v)$ are learned and optimised during training. The trained GPR model is then applied to  validation datasets corressponding to new realisations of the dephasing process. In each case, the statistical likelihood of the dataset constrains the trained model, yielding an aposteriori predictive distribution where the mean of this predictive distribution are the state predictions for the qubit under dephasing. 
\\
\\
Formally, the predictive equations for GPR are obtained as follows. Let indices $n,m \in N_T \equiv [-N_T, 0]$ denote training points, and $n^*,m^* \in N^* \equiv [-N_T, N_P]$ denote testing points in machine learning language. We now define the joint distribution $P(y,\state^*)$, where $\state^*$ is our prediction for the true process at test points: 
\begin{align}
\begin{bmatrix} \state^* \\y \end{bmatrix} & \sim \mathcal{N} (\begin{bmatrix} \mu_{\state^*} \\ \mu_y
\end{bmatrix} , \begin{bmatrix}   K(N^*,N^*)&K(N_T,N^*) \\ K(N^*,N_T) & K(N_T,N_T) + R \end{bmatrix} )
\end{align}
Following \cite{rasmussen2006}, the moments of the conditional distribution $P(\state^*|y)$ can be derived from the joint distribution $P(y,\state^*)$ via standard Gaussian identities:
\begin{align}
\mu_{\state^*|y} &= \mu_\state + K(N^*,N_T)(K(N_T,N_T) + R )^{-1} (y - \mu_y) \\
\Sigma_{\state^*|y} &= K(N^*,N^*) \nonumber \\
& - K(N^*,N_T)(K(N_T, N_T) + R)^{-1}K(N_T,N^*) 
\end{align}
The above prediction procedure holds true for any choice kernel, $R(v)$. The aposteriori mean, $\mu_{\state^*|y}$ yield predictions of qubit state at test points $N^*$.
\\
\\
Our choice of $R(v)$ as the sine squared exponential, or the `Periodic', kernel allows us to reconstruct any covariance stationary process $f$ in the mean square limit. In the Supplementary Information, we follow \cite{solin2014} to show that a sine squared exponential kernel represents an infinite basis of oscillators, and reduces to the covariance function describing trigonometric polynomials if spectral components are truncated to a finite number, $J$:
\begin{align}
R(v) &\equiv \sigma^2 \exp (- \frac{2\sin^2(\frac{\omega_0 v}{2})}{l^2}) \\
% R(v) &=  \sigma^2 \exp (- \frac{1}{l^2}) \sum_{n = 0}^{\infty} \frac{1}{n!} \frac{\cos^n(\omega_0 v)}{l^{2n}} \\
R(v) &- \sigma^2 p_{0,J}  = \sigma^2 \sum_{j=0}^{J} p_{j,J} \cos(j\omega_0 v)\\
p_{0,J} & \equiv \frac{1}{2} \exp (- \frac{1}{l^2}) \sum_{\alpha = 0}^{\alpha = \lfloor\frac{J}{2}\rfloor} \frac{1}{(2l^2)^{(2\alpha)}} \frac{1}{(2\alpha)!} \binom{2\alpha}{\alpha} \label{eqn:p0J}\\
p_{j,J} & \equiv \exp (- \frac{1}{l^2}) \sum_{\beta = 0}^{\beta = \lfloor\frac{J-j}{2}\rfloor} \frac{2}{(2l^2)^{(j + 2\beta)}} \frac{1}{(j + 2\beta)!} \binom{j + 2\beta}{\beta} \label{eqn:pjJ} \\
\omega_0 &\equiv \frac{\omega_j}{j}, j \in \{0, 1,..., J\} 
\end{align}
We note that the sine-squared kernel is summarised by two key hyper-parameters: the frequency comb spacing for our infinite basis of oscillators, $\omega_0$, and a dimensionaless length scale, $l$. We use physical sampling considerations to approximate their intial conditions prior to an optimisation procedure, namely, that the longest correlation length encoded in the data, $\Delta t N$, sets the frequency resolution of the comb, and the scale at which changes in $f$ are resolved is of order  $\Delta t$:
\begin{align}
\frac{\omega_0}{2\pi} & \sim  \frac{1}{\Delta t N} \\
l & \sim \Delta t
\end{align}
We briefly summarise kernel choices excluded from our analysis, including popular choices such as the Gaussian kernel (RBF); a scale mixture of Gaussian kernels (RQ); the Matern family of kernels; and a spectral mixture of Gaussian kernels. These exclusions are based on kernel properties as follows. An arbitrary scale mixture of zero mean Gaussian kernels will probe an arbitrary area around zero in the Fourier domain, as schematically depicted in \cref{fig:main:paper_fig_1}(d). While such kernels capture the continuity assumption ubitiquous in machine learning, they appear structurally disadvantaged in probing a dephasing noise process of an arbitrary power spectral density (e.g. ohmic noise).  Matern kernels of order $q + 1/2$ correspond to a certain class of random process, known as autoregressice processes of order $q$, which are naturally considered under state space Kalman models in this paper. We do not duplicate our investigations under GPR. A class of GPR methods, namely, spectral mixture kernels and sparse spectrum approximation using GPR have been explored in \cite{wilson2013, quia2010}. These require efficient optimisation procedures to learn a large number of unknown kernel parameters, wherease the sine-squared exponential is parameterised only by two hyper-parameters. A detailed investigation of the application of these spectral methods for forward prediction beyond pattern recognition, with limited computational resources, is beyond the scope of this paper.  

\subsection{KF}
In a Kalman framework, we track a hidden true state, $x$, which cannot be observed without incurring measurement noise, yielding observations $y$. The hidden state $x$ is propagated according to a dynamical model $\Phi$ but this dynamical evolution is subject to additional `process noise'. A Kalman filter estimates the true $x$ by filtering out measurement noise from observed outcomes and tracking the hidden state over a noisy trajectory. In this context, we imagine that abstract Gaussian white process noise is shaped by  a matrix $\Gamma$ and is deterministically colored by the dynamical model $\Phi$ to yield a non-Markovian hidden true Kalman state. The interpretation of the Kalman state $x$ depends the specific choice of design matrices $\{ \Phi, H, \Gamma\}$. In particular, $\Phi$ is constructed such that any arbitrary covariance stationary process can be probed and tracked in the mean square limit. Formally, the state space system under consideration is:
\begin{align}
y_n &= z_n + v_n \\
z_n & \equiv  h(x_n) \\
x_n & = \Phi_n x_{n-1} + \Gamma_n w_n \label{eqn:KF:dynamics} \\
w_n & \sim \mathcal{N}(0, \sigma^2) \quad \forall n \\
H_n &\equiv \frac{d h(x_n)}{dx_n}  
\end{align}
Kalman approaches have been adapted to track non linear state dynamics and/or non linear measurement models. In particular, the Jacobians of non linear $ \Phi(x)$ and/ or $h(x)$, are used to propagate state estimates and this procedure works if errors from linearisation remain small. In our application,$\Phi$  is always linear but we have a non linear measurement action defined by \cref{eqn:main:likelihood}. 
\\
\\
In addition to a non linear measurement action, we obtain quantised measurement outcomes. A state space approach can incorporate quantised measurement information \cite{karlsson2005}, and we represent this notationally as:
\begin{align}
d_n &= \mathcal{Q}(y_n) = \mathcal{Q}(z_n + v_n)
\end{align}
In the linear measurement regime, $h(x_n) \mapsto H_nx_n$ and $f_n \equiv H_n x_n$, and no quantisation is necessary.
\\
\\
In what follows, we describe the Kalman state $x$ and the specific choice of design matrices $\{ \Phi, H, \Gamma \}$ which completely specify the Kalman algorithms in this paper by making the relevant substitutions in the equations above. The remaining design parameters, $\sigma^2, R$, are trained using optimisation procedures prevalent in machine learning. 

\subsubsection{AKF}
Our first Kalman implementation will probe arbitrary, covariance stationary qubit dynamics by  where the dynamical model  is such that $f_n$ is the weighted sum of $q$ past values. The rationale for defining $\Phi$ in this manner is that any zero mean covariance stationary process has a representation in the mean square limit by an autoregressive process of order $q_m$, AR($q_m$), where convergence to true process falls with $m$. The study of AR($q$) processes falls under the study of a general class of techniques based on autoregressive moving average (ARMA) models in classical control engineering. Our AR($q$) process is defined as:
\begin{align}
\Phi(L) f_n & = w_n \\
\Phi(L) & \equiv  1 - \phi_1 L - \phi_2 L^2 - ... - \phi_q L^q \\
L^r: f_n &\mapsto f_{n-r} \quad \forall r \leq n \quad \text{(lag operator)} 
\end{align}
Here, $\Phi(L)$ is a dynamical model summarised in terms of a lag operator. 
\\
\\
Any AR($q$) process can be recast (non-uniquely) into state space form easily by substituting the following definitions into Kalman equations:
\begin{align}
x_n & \equiv  \begin{bmatrix} f_{n} \hdots f_{n-q+1} \end{bmatrix}^T \\
\Gamma_n w_n & \equiv \begin{bmatrix} w_{n} 0 \hdots 0 \end{bmatrix}^T \\
\Phi_{AKF} & \equiv 
\begin{bmatrix}
\phi_1 & \phi_2 & \hdots & \phi_{q-1} & \phi_q \\ 
1 & 0 & \hdots & 0 & 0 \\  
0 & 1 & \ddots & \vdots & \vdots \\ 
0 & 0 & \ddots & 0 & 0 \\ 
0 & 0 & \hdots & 1 & 0 
\end{bmatrix} \quad \forall n \label{eqn:akf_Phi} \\
H & \equiv \begin{bmatrix} 1 0 \hdots 0 \end{bmatrix} \quad \forall n 
\end{align}
The matrix $\Phi_{AKF}$ is the dynamical model used to recursively propagate the unknown state during state estimation in the AKF. The ${\phi_i}$ in $\Phi_{AKF}$ are ideally the output of a maximum likelihood optimisation problem during training, where the total number of parameters to be optimised are $\{\phi_1, \hdots, \phi_q, \sigma^2, R \}$. This procedure yields the optimal configuration of the autoregressive Kalman filter, but at the computational cost of a $q+2$ dimensional optimisation problem for arbitrarily large $q$.
\\
\\
The Least Squares Filter (LSF) in \cite{mavadia2017} considers a weighted sum of past measurements to predict the $n$-th step ahead measurement outcome. A gradient descent algorithm is used directly learn the weights, $\{\phi_j\}, j = 1, ... , q $, of the previous $q$ past measurements for each value of $n$. These $n$ models, collectively, define the set of predicted outcomes in $n \in [0, N_P]$. For $n=1$, the LS Filter in \cite{mavadia2017} approximately implements an AR($q$) process, where the one-step ahead prediction is given as a weighted linear sum of past measurements. This offers us an opportunity to side-step the maximum likelihood optimisation problem for AKF by using ${\phi_i}$ from LSF to define $\Phi_{AKF}$. Since Kalman noise parameters ($\sigma^2, R$) are subsequently auto-tuned using a Bayes Risk optimisation procedure, we optimise over potentially remaining model errors and measurement noise while reducing the computational burden of solving the full $q+2$ dimensional maximum likelihood optimisation problem. 
\\
\\
The set of trained parameters, $\{\phi_1, \hdots, \phi_q, \sigma^2\}$ from LSF and AKF allows us to other predict experimentally measurable quantities, for example, we can recover the power spectral density of the dephasing process using standard results on AR($q$) processes [CEHCK]:
\begin{align}
S(\omega) & = \frac{\sigma^2}{2 \pi }\frac{1}{|\Phi(e^{-i\omega})|^2} \label{eqn:sec:ap_ssp_ar_spectden} 
\end{align}
While AKF recasts the dynamics of LSF in recursive form, the predictive performance from LSF in \cite{mavadia2017} is expected to be equivalent to AKF in low measurement noise regimes as they share a common dynamical model. In high measurement noise regimes, a Kalman framework should enable additional measurement noise filtering through the regularising effect of $R$. 

\subsubsection{LKFFB}

We now use a Kalman filter to probe dephasing noise over a fixed bandwidth and use learned information to enable state predictions.
\\
\\
Our objective is to project our measurement record on $J$ oscillators with fixed frequency $\{ \omega_0 j, j = 1, \hdots, J \}$, while learning the amplitude and phase of these oscillators using a Kalman filter developed in \cite{livska2007}, denoted as a Liska Kalman Filter (LKF) in this paper. In LKF, we track the real and imaginary parts of the Kalman state  simultaneously in order calculate the instantaneous amplitudes ($\norm{x^j_n}$) and phases ($\theta_{x^j_n}$)  for each Fourier component explicitly. By specifying a fixed basis of oscillators in the LKF, we define the Liska Kalman Filter with a Fixed Basis (LKFFB). We may probe dephasing noise to an arbitrarily high resolution for tracking qubit dynamics by choosing an arbitrarily high value for the ratio $J/\omega_0$.
\\
\\
The following substitutions into Kalman equations, and the choice of fixed basis specified in Supplementary information, defines the LKFFB algorithm:
\begin{align}
x_n & \equiv \begin{bmatrix} x^{1}_{n} \hdots x^{j}_{n} \hdots x^{J}_{n} \end{bmatrix} \\
x^{j,1}_{n} & \equiv \text{estimates real $f$ component for $\omega_j$} \\
x^{j,2}_{n} & \equiv \text{estimates imaginary $f$ component for $\omega_j$} \\
x^j_n &\equiv \begin{bmatrix} x^{j,1}_{n} \\ x^{j,2}_{n} \\ \end{bmatrix} \equiv \begin{bmatrix} A^j_{n} \\ B^j_{n}  \end{bmatrix}\\
\norm{x^j_n} & \equiv \sqrt{(A^j_{n})^2 + (B^j_{n})^2} \\
\theta_{x^j_n} & \equiv \tan{\frac{B^j_{n}}{A^j_{n}}} \\
\Gamma_{n-1} &\equiv \Phi_{n-1}\frac{x_{n-1}}{\norm{x_{n-1}}}  \\
H & \equiv \begin{bmatrix} 1 0 \hdots 1 0 \hdots 1 0 \end{bmatrix}
\end{align}
We note that process noise feature matrix $\Gamma_{n}$ depends on state estimates and hence, state variance propagation via the Ricatti equation cannot be decoupled from state estimation, as in traditional Kalman implementations. This means that the performance of the filter and pre-calculations of the Kalman gain are not permitted in this implementation. Instead, we track and assess learned instantaneous amplitude, phase, and residual information to catalogue filter performance during learning. 
\\
\\
By using block diagonal matrices to stack $\Phi(j \omega_0 \Delta t) $ for all $\omega_j$, we obtain the full dynamical model $\Phi_n$:
\begin{align}
\Phi_{n} & \equiv \begin{bmatrix} 
\Phi(\omega_0 \Delta t)\hdots 0  \\ 
 \hdots \Phi(j\omega_0 \Delta t) \hdots \\
0 \hdots \Phi(J \omega_0 \Delta t)  \end{bmatrix}\\ 
\Phi(j \omega_0 \Delta t) &\equiv \begin{bmatrix} \cos(j \omega_0 \Delta t) & -\sin(j \omega_0 \Delta t) \\ \sin(j \omega_0 \Delta t) & \cos(j \omega_0 \Delta t) \\ \end{bmatrix} \label{eqn:ap_approxSP:LKFFB_Phi} 
\end{align}
In particular, one obtains the same mathematical structure if one defined a stack of independent Markovian stochastic processes on a circle, as in \cite{karlin2012}, with proofs deferred to Supplementary Information. 

\subsubsection{QKF}

While the previous algorithmic implementations have focused on the incorporation of non-Markovian dynamics under a linear measurement model, we shift our focus to freezing a dynamical model and investigating the effects of a non-linear, quantised measurement action (QKF). In particular, we extend the AKF framework to a non linear measurement action, $h(x_n)$, and quantised outcomes, captured by $\mathcal{Q}$. 
\\
\\
Formally, we retain the dynamical equation with identical definitions of $x, \Phi, \Gamma$, as in AKF.  However, the measurement model in the QKF framework is redefined to a non linear measurment action as:
\begin{align}
z_n & \equiv  h(x_n) \equiv h(x_n[0]) \\
& = h(\state_n)h(\state_n) \\
& \equiv  0.5\cos(\state_{n}) \\
H_n &\equiv \frac{d h(\state_n)}{d\state_n} =  -0.5\sin(\state_{n})
\end{align}
We mimic the naturally quantised qubit by $\mathcal{Q}$  in the Kalman Filter by performing a biased coin flip, where the bias of the coin is given by $y_n$ and $\mathcal{B}$ as the binomial distribution: 
\begin{align}
\mathcal{Q}(y_n): &\quad  d_n \sim \mathcal{B}(d_n=1; n=1, p= y_n + 0.5 | y_n, t) 
\end{align}
The rationale for enabling this quantisation procedure comes from the statistical study for amplitude quantisation of analogue signals using an $m$-bit quantiser, where the continous amplitudes of a analogue signal are discreted into $2^m$ levels. In our application, the continous amplitude trace, while not a real signal, is the likelihood function in \cref{eqn:main:likelihood}. This function is discretised in allowed values of $ [0,1]$. Such a discretisation procedure corressponds to amplitude quantisation using a single bit ($m=1$) quantiser, in classical engineering, but further modified to allowed for biased coin flips described by $\mathcal{Q}$. 
\\
\\
In \cref{fig:main:paper_fig_1}, $\mathcal{Q}$ defines the likelihood of measurment outcomes $d_n$ given $x_n$ having marginalised over all possible values of $y_n$. The convolution of the Gaussian distributed $y_n$ with a uniform distribution is a theoretical construct for the numerical need to saturate $y$ for allowed values $y \in [-0.5, 0.5]$. Details of this  scheme are provided in Supplementary Information. The net result is a non-linear, quantised measurement action which is defined in QKF when the measurement record are single shot qubit outcomes depicted in \cref{fig:main:paper_fig_1} (c).


\section{Optimisation}  \label{sec:main:3}

In the absence of apriori knowledge of statistics of environmental dephasing, we require an optimisation procedure to tune Kalman design parameters ($\sigma^2, R$). For the simulations considered in this paper, we calculate the Bayes Risk - the mean square distance between truth and prediction sequences for different realisations of true $\state$ and different noisy datasets $\mathcal{D}$:
\begin{align}
L_{BR}(\state) & \equiv \sum^{N}\ex{(\state_n - H_n\hat{x_n})^2}_{\state,\mathcal{D}} \label{eqn:sec:ap_opt_LossBR}
\end{align}
State estimation risk is Bayes Risk incurred during $n \in [0, N_T]$; prediction risk is the Bayes Risk incurred during $n \in [N_T, N_T + N_P]$. 
\\
\\
For arbitrary power spectral densities of dephasing noise, the optimisation problem posed above is extremely difficult to solve with standard local optimisers. Firstly, we have no theoretical bounds on the values of ($\sigma^2, R$). This generates large, flat regions of Bayes Risk which are difficult for many of the standard local optimisers to traverse. Such a failure can be diagnostically be reproduced by engineering narrow dips on large, flat plains and documenting the performance of standard gradient and simplex algorithms in finding these features, as in Supplementary Materials. An additional issue is that the recursive structure of the Kalman filter means that no analytical gradients are accessible  for optimising the Bayes Risk function, and this generates a large computational burden. Beyond standard gradient and simplex optimisers, we consider coordinate ascent CITE and particle swarm optimisation techniques as promising, nascent candidates and their application remains an open research question. 
\\
\\
For the purposes of results in this paper, we uniformly distribute ($\sigma^2, R$) pairs over several orders of magnitudes. The pair with the lowest state estimation Bayes Risk below a specified threshold is chosen as the best available candidate. For each investigation, we check that our procedure has meaningful interpretation by comparing low loss regions for state estimation and prediction. If the lowest state estimation risk is also incurred for low loss regions during prediction, and the candidate falls within this overlap region, then the KF filter is sensibly tuned. If an overlap of low loss regions  for state estimation and prediction do not exist, or if the optimal candidate does not reside in the overlap region, then the optimisation problem is deemed `broken' as algorithm training cannot improve prediction performance. 

\section{Algorithm Performance Characterisation}  \label{sec:main:4}

\subsection{Linear Bayesian Models}
Performance characterisation focuses on learning stochastic dynamics for enabling maximal prediction horizon.
\begin{itemize}
\item Fig: GPR-P predictions not possible to interpret sensibly (excluded from analysis)
\item Fig: LSF / AKF outperforms LKFFB when perfect projection is not possible
\item Fig: Spectrum reconstruction suggests phase information tracking is worse than ampitude tracking for explaining LKFFB failure in imperfect environments
\item Fig: Model pathologies reflected in the underlying optimisation problem provides further evidence for AKF model robustness
\item Fig: Increased measurement noise filtering from LSF to AKF
\end{itemize}

Qn: add Cramer Rao recursions to the above implementations?

\subsection{Non Linear, Quantised State Space Models}
Performance characterision focuses on whether it is possible to extend state space models for binary outcomes in our application if true dynamics were known, and modelled using an AKF framework.

First, introduce a quantisation (numerically) into the Kalman Filter. We focus on state estimation without prediction. 
\begin{itemize}
\item Fig: True vs. Learned LSF dynamics for AR(2) problem
\item Fig: Cramer Rao Bounds show no difference to our nnumerical quant procedure
\end{itemize}

However, the violations show that non linearities and truncation errors accumulate in the recursion of the Bounds. 
\\
\\
In terms of predictive performance with a perfect learning case:
\begin{itemize}
\item Fig: True vs. Learned LSF dynamics for perfect learning regime, but adapt predictions such that $y$ is the output not $d$
\end{itemize}
\section{Conclusion}  \label{sec:main:5}

