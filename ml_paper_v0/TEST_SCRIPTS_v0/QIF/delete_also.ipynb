{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quantised Kalman Filter\n",
    "\n",
    "References\n",
    "\n",
    "[1]\n",
    "\n",
    "[2]\n",
    "\n",
    "The quantised kalman filter (QKF) incorporates a dynamical model of the auto-regressive kalman (AKF) filter and a measurement model that is (a) non linear and (b) a coin flip measurement action.\n",
    "\n",
    "In this script, we test whether the measurement action works by feeding in the true model into the filter (via autoregressive coeffcients, true process noise variance and true noise variance) and by performing the full learning procedure as for a typical AKF implementations. We use Test Case 24 and its variations to change the oversampling ratio and to characterise the performance of the QKF with true and learned filter design parameters. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The list q_regime stores the autoregressive weights for each Test Case variation. These weights will be used to define (a) a stochastic truth, f', such that QKF is  perfectly specified, and (b) the learned dynamical model with respect to true, f, in the sense that learning is imperfect. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "q_regime=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PREAMBLE COMMANDS ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../../')\n",
    "\n",
    "#### Local QIF Filter and Helper Functions ####\n",
    "from qif.qif import qif as qif\n",
    "from qif.common import generate_AR, noisy_z, projected_msmt, qkf_state_err, normalise\n",
    "from ls.common import doLSF_forecast\n",
    "\n",
    "#### Local Plotting Tools ####\n",
    "from plot_tools.fig_preamble import *\n",
    "from plot_tools.plot_figstyle_sheet import STYLEDICT, COLOURDICT\n",
    "from plot_tools.plot_helper_funcs import cm2inch\n",
    "\n",
    "#### Matplotlib & Numpy ####\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "mpl.rc('font', size=8)\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import ScalarFormatter, FormatStrFormatter\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "\n",
    "#### Global Plotting and Saving Commands ####\n",
    "\n",
    "############ Saving Commands #########\n",
    "\n",
    "ver=0\n",
    "datapath = '../../DATA_v'+str(ver)+'_/' #v'+str(ver)+'/DATA_v'+str(ver)+'/'\n",
    "savefig = './analysis_figs'\n",
    "figname = 'tc_24_scan'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AKF: Data Loaded? Yes\n",
      "AKF: Data Loaded? Yes\n",
      "AKF: Data Loaded? Yes\n",
      "AKF: Data Loaded? Yes\n",
      "AKF: Data Loaded? Yes\n"
     ]
    }
   ],
   "source": [
    "# We want to load a high order AR(q) model where we know that underlyign truth is stationary.\n",
    "\n",
    "from data_tools.load_raw_cluster_data import LoadExperiment\n",
    "\n",
    "test_case = 24\n",
    "variation_scan = [1, 2, 3, 4, 7]\n",
    "\n",
    "for idx_var in variation_scan:\n",
    "    experiment = LoadExperiment(24, idx_var, \n",
    "                                LKFFB_load ='No',\n",
    "                                LSF_load='No',\n",
    "                                AKF_load='Yes', \n",
    "                                AKF_path=datapath,\n",
    "                                GPRP_load='No')\n",
    "\n",
    "    # We will now gradually move into the high q regime by considering the following weights:\n",
    "    q_regime.append(experiment.AKF_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Noise Parameters\n",
    "\n",
    "In order to generate our true process, we will keep the following process noise and measurement noise parameters the same, and we will feed the true values into QIF to side step auto-tuning of parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "######## True Process Noise Strength\n",
    "true_oe = 0.1**2\n",
    "######## True Msmt Noise Strength\n",
    "true_rk = 0.1**2\n",
    "####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up of Algorithm Parameters (QKF, LSF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###### Number of data points and initial points to exclude (burnin) #####\n",
    "num = 2050\n",
    "burn_in = 500\n",
    "\n",
    "###### AR Process Initialisation #####\n",
    "# we need phases to accumulate from 0 to pi. So our process is no longer mean zero.\n",
    "mean_noise = 0.5*np.pi\n",
    "\n",
    "###### Bayes Risk Runs ######\n",
    "runs = 50\n",
    "\n",
    "########### LSF ##############\n",
    "pick_alpha=0.1\n",
    "n_predict = 50\n",
    "n_train=num-n_predict\n",
    "num_of_iterGD = 50\n",
    "\n",
    "########### KF ##############\n",
    "p0init = 1000 # set same as AKF /LSF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Run 100 times; with QKF using true dynamics and LSF learned dynamics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('The true weights are of order: ', 101)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-df5624b20a74>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     40\u001b[0m         object_ = doLSF_forecast(measurements_train, measurements_val, pick_alpha, \n\u001b[1;32m     41\u001b[0m                            \u001b[0mn_start_at\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_predict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m                            steps_between_msmts=1, num_of_iterGD=num_of_iterGD)\n\u001b[0m\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m         \u001b[0;31m# Generate validation dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/riddhisw/Documents/2017/Scripts_Git/ls/common.pyc\u001b[0m in \u001b[0;36mdoLSF_forecast\u001b[0;34m(measurements_train, measurements_val, pick_alpha, n_start_at, n_predict, past_msmts, steps_between_msmts, num_of_iterGD)\u001b[0m\n\u001b[1;32m     43\u001b[0m                         steps_between_msmts=steps_between_msmts)\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m                 \u001b[0mweights_tuned\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrorTrain_fore\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx_steps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgradient_descent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_of_iterGD\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha_coeff\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpick_alpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m                 validation_data = sp.build_training_dataset(measurements_val, \n",
      "\u001b[0;32m/home/riddhisw/Documents/2017/Scripts_Git/ls/statePredictions.pyc\u001b[0m in \u001b[0;36mgradient_descent\u001b[0;34m(training_data, numIters, alpha_coeff)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         gradient[:,0] = np.sum(gradient_summand(weights,actual_values,  \n\u001b[0;32m--> 152\u001b[0;31m                                             past_measurements),axis=0) # Sum up all the rows in gradient_summand\n\u001b[0m\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0malpha_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malpha\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/riddhisw/Documents/2017/Scripts_Git/ls/statePredictions.pyc\u001b[0m in \u001b[0;36mgradient_summand\u001b[0;34m(weights, actual_values, past_measurements)\u001b[0m\n\u001b[1;32m     89\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mone\u001b[0m \u001b[0mparticular\u001b[0m \u001b[0mprediction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m             '''\n\u001b[0;32m---> 91\u001b[0;31m     \u001b[0mgSummands\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpast_measurements\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mactual_values\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mpast_measurements\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mgSummands\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "norm_z_states_=[]\n",
    "\n",
    "# idx_q_regime walks through test case 24 and its variations\n",
    "for idx_q_regime in xrange(len(q_regime)):\n",
    "\n",
    "\n",
    "    # Pick the AR(q) regime of coefficients\n",
    "    true_weights = q_regime[idx_q_regime]\n",
    "    order = true_weights.shape[0]\n",
    "    n_start_at=n_train - order + 1\n",
    "    \n",
    "    print(\"The true weights are of order: \", order)\n",
    "\n",
    "    # Set random initial conditions. These apply to the entire experiment.\n",
    "    x_init = np.random.uniform(low=-0.5*np.pi, high=0.5*np.pi, size=order)\n",
    "\n",
    "    # We store the residuals and the x_hat \n",
    "    x_true_dynamics = np.zeros((runs, order, num))\n",
    "    x_LSF_dynamics = np.zeros((runs, order, num))\n",
    "\n",
    "    gain_true_dynamics = np.zeros((runs, order, num))\n",
    "    gain_LSF_dynamics = np.zeros((runs, order, num))\n",
    "\n",
    "    truths_ = np.zeros((runs, num))\n",
    "    err_true_dynamics = np.zeros((runs, num))\n",
    "    err_LSF_dynamics = np.zeros((runs, num))\n",
    "\n",
    "\n",
    "    ######### Make an ensemble of QIF experiments ############\n",
    "\n",
    "    for idx_run in xrange(runs):\n",
    "\n",
    "        # Make truth for one run\n",
    "        true_x = generate_AR(x_init, num + burn_in, true_weights, true_oe)[burn_in:] + mean_noise \n",
    "        truths_[idx_run, :] = true_x # this is mean 0.5 pi\n",
    "        noisy_z_ = noisy_z(true_x, true_rk) # this is mean zero\n",
    "\n",
    "        # Find LSF weights using quantised msmts\n",
    "        measurements_train = projected_msmt(noisy_z_)\n",
    "        measurements_val = projected_msmt(noisy_z_) # true_x doesnt change\n",
    "        object_ = doLSF_forecast(measurements_train, measurements_val, pick_alpha, \n",
    "                           n_start_at, n_predict, order, \n",
    "                           steps_between_msmts=1, num_of_iterGD=num_of_iterGD)\n",
    "\n",
    "        # Generate validation dataset\n",
    "        y_signal = projected_msmt(noisy_z_)\n",
    "\n",
    "        # Run QIF using True Dynamics \n",
    "        predictions, W, x_hat, P_hat, err_true_dynamics[idx_run, :] = qif('truedynamics', y_signal, \n",
    "                                                                          true_weights, true_oe, true_rk, \n",
    "                                                                          n_train=n_train, \n",
    "                                                                          n_testbefore=n_predict, \n",
    "                                                                          n_predict=n_predict, \n",
    "                                                                          p0=p0init, skip_msmts=1,  \n",
    "                                                                          save='No')\n",
    "        # Run QIF using LSF Learned Dynamics \n",
    "        predictions_l, W_l, x_hat_l, P_hat_l, err_LSF_dynamics[idx_run, :] = qif('lsfdynamics', y_signal, \n",
    "                                                                                 object_[1][1].ravel() , \n",
    "                                                                                 true_oe, true_rk, \n",
    "                                                                                 n_train=n_train, \n",
    "                                                                                 n_testbefore=n_predict, \n",
    "                                                                                 n_predict=n_predict, \n",
    "                                                                                 p0=p0init, \n",
    "                                                                                 skip_msmts=1, save='No')\n",
    "        # Store run for this experiment\n",
    "        x_true_dynamics[idx_run, :, :] = x_hat[:,0,:]\n",
    "        x_LSF_dynamics[idx_run, :, :] = x_hat_l[:,0,:]\n",
    "\n",
    "#         gain_true_dynamics[idx_run, :, :] = W[:,0,:]\n",
    "#         gain_LSF_dynamics[idx_run, :, :] = W_l[:,0,:]\n",
    "        \n",
    "#         np.savez(datapath+'QIF_BayesPredRisk_v_OverSampl_v0_Final.npz', \n",
    "#                  # norm_z_states_=norm_z_states_, \n",
    "#                  z_true_dynamics=z_true_dynamics,\n",
    "#                  x_true_dynamics=x_true_dynamics,\n",
    "#                  x_LSF_dynamics=x_LSF_dynamics,\n",
    "#                  q_regime=q_regime,\n",
    "#                  truths_=truths_)\n",
    "\n",
    "    ######### Calculate Bayes Risk with respect to z for each experiment ############\n",
    "\n",
    "    z_true_dynamics = np.asarray([noisy_z(sequence, 0.) for sequence in x_true_dynamics[:, 0, 0:num]])\n",
    "    z_LSF_dynamics = np.asarray([noisy_z(sequence, 0.) for sequence in x_LSF_dynamics[:, 0, 0:num]])\n",
    "\n",
    "    ######### Calculate Bayes Risk for predicting mean z = 0.5cos(f_n) == 0  ############\n",
    "    truths_z = np.asarray([noisy_z(sequence, 0.) for sequence in truths_[:, 0:num]])\n",
    "    predict_one = np.mean((truths_z)**2, axis=0)\n",
    "\n",
    "    ######### Normalise Bayes Risk  ############\n",
    "\n",
    "    norm_z_states_.append([(qkf_state_err(z_true_dynamics[:, :], truths_z)) / predict_one, \n",
    "                      (qkf_state_err(z_LSF_dynamics[:, :], truths_z)) / predict_one])\n",
    "    \n",
    "    np.savez(datapath+'QIF_BayesPredRisk_v_OverSampl_v0_Final.npz', \n",
    "             norm_z_states_=norm_z_states_, \n",
    "             z_true_dynamics=z_true_dynamics,\n",
    "             x_true_dynamics=x_true_dynamics,\n",
    "             x_LSF_dynamics=x_LSF_dynamics,\n",
    "             q_regime=q_regime,\n",
    "             truths_z=truths_z)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "np.savez(datapath+'QIF_BayesPredRisk_v_OverSampl_v0_Final.npz', \n",
    "         norm_z_states_=norm_z_states_) \n",
    "#          z_true_dynamics=z_true_dynamics,\n",
    "#         truths_z=truths_z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "labels = [r'QKF(True $\\Phi)$', r'QKF(AKF $\\Phi$)', r'']\n",
    "color = [COLOURDICT['QKF'], COLOURDICT['AKF']] # By algorithm\n",
    "figstyl = ['-', 'o', 'x', 's', ':']  # By regime \n",
    "\n",
    "\n",
    "gs = gridspec.GridSpec(1, 2,\n",
    "                       left=0.1, right=0.99, \n",
    "                       top=0.99, bottom=0.1, \n",
    "                       wspace=0.1, hspace=0.1)\n",
    "\n",
    "fig = plt.figure(figsize=(cm2inch(8),cm2inch(3.)))\n",
    "ax_0 = fig.add_subplot(gs[0, 0])\n",
    "ax_1 = fig.add_subplot(gs[0, 1])\n",
    "\n",
    "\n",
    "\n",
    "for idx_algo in xrange(2):\n",
    "    \n",
    "    for idx_q_regime in xrange(len(q_regime)):\n",
    "        \n",
    "        alpha_gradient = 1.0 - 0.12*idx_q_regime\n",
    "        \n",
    "        vars()['ax_'+str(idx_algo)].plot(np.arange(0, n_predict, 2), \n",
    "                                   norm_z_states_[idx_q_regime][idx_algo][n_train : num : 2], \n",
    "                                   figstyl[idx_q_regime], \n",
    "                                   label=labels[idx_algo], \n",
    "                                   c=color[idx_algo],\n",
    "                                   markeredgecolor=color[idx_algo],\n",
    "                                   alpha=alpha_gradient,\n",
    "                                   markerfacecolor=\"None\", ms=3,lw=1)\n",
    "        \n",
    "    vars()['ax_'+str(idx_algo)].margins(0.2)\n",
    "    vars()['ax_'+str(idx_algo)].set_yscale('log')\n",
    "    vars()['ax_'+str(idx_algo)].set_xscale('log')\n",
    "    vars()['ax_'+str(idx_algo)].axhline(y=1.0, c=COLOURDICT['TRUTH'])\n",
    "    vars()['ax_'+str(idx_algo)].yaxis.set_major_formatter(FormatStrFormatter('%.0f'))\n",
    "    #vars()['ax_'+str(idx_algo)].yaxis.set_minor_formatter(FormatStrFormatter('%.0f'))   \n",
    "    vars()['ax_'+str(idx_algo)].tick_params(direction='in', which='both')\n",
    "    vars()['ax_'+str(idx_algo)] = set_font_sizes(vars()['ax_'+str(idx_algo)], fsize, Fsize)\n",
    "    vars()['ax_'+str(idx_algo)].yaxis.set_major_locator(ticker.LogLocator(base=10, numticks=2))\n",
    "    vars()['ax_'+str(idx_algo)].set_ylim([0.1, 20])\n",
    "\n",
    "ax_0.set_ylabel(r'$\\langle (f_n -\\hat{f_n})^2 \\rangle_D$')\n",
    "\n",
    "# ax_0.set_ylim([0.6,3.0])\n",
    "\n",
    "fig.savefig(savefig+figname+'.svg', format='svg', dpi=400)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
