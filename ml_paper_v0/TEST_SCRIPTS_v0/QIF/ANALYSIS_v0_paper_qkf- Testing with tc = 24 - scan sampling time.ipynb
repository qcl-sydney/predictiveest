{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to test the performance of a QIF framework for non-Markovian, covariance stationary process using non-linear quantised measurements.\n",
    "\n",
    "#### TRUE DYNAMICS\n",
    "\n",
    "We want to specify the true dynamics of QIF exactly such that only the measurement model is tested. To do this, we suggest that we will define the coefficients of an AR(q) process. We will use these coefficients to generate (a) a true sequence for f_n and (b) we are able to input the true coefficents into the dynamical model of QIF. Hence, true dynamics in QIF, in principle, can be exactly specified. \n",
    "\n",
    "However, this is  practically problematic:\n",
    "\n",
    "- For low q, it is analytically possible to figure out what the AR coefficients should look like such that our truth is covariance stationary and non Markovian. We can use these analytic bounds to specify the coefficients such that f_n remains covariance stationary and non Markovian. However, low q regime is not comparable with regime that we have considered in the past, namely, that f_n was learned well if and only if q was large > 100\n",
    "\n",
    "- For high q, no analytic solutions are available. We make an assumption than a LSF acting on covariance stationary, non Markovian f_n defines approximately the sorts of dynamics and power spectrum that we are looking for. We take these weights from LSF, and we define these to be \"true\" coefficients of an AR process that is comparable to f_n covariance stationary, non Markovian.\n",
    "\n",
    "#### ASSESSMENT\n",
    "\n",
    "We will assess QIF performance for tracking the likelihood z = 0.5 cos(f_n) in the low and high q regime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "q_regime=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PREAMBLE COMMANDS ####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../../../')\n",
    "\n",
    "#### Local QIF Filter and Helper Functions ####\n",
    "from qif.qif import qif as qif\n",
    "from qif.common import generate_AR, noisy_z, projected_msmt, qkf_state_err, normalise\n",
    "from ls.common import doLSF_forecast\n",
    "\n",
    "#### Local Plotting Tools ####\n",
    "from plot_tools.fig_preamble import *\n",
    "from plot_tools.plot_figstyle_sheet import STYLEDICT, COLOURDICT\n",
    "from plot_tools.plot_helper_funcs import cm2inch\n",
    "\n",
    "#### Matplotlib & Numpy ####\n",
    "import numpy as np\n",
    "import matplotlib as mpl\n",
    "mpl.rc('font', size=8)\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import ScalarFormatter, FormatStrFormatter\n",
    "import matplotlib.gridspec as gridspec\n",
    "\n",
    "\n",
    "#### Global Plotting and Saving Commands ####\n",
    "\n",
    "############ Saving Commands #########\n",
    "\n",
    "ver=0\n",
    "datapath = '../../DATA_v'+str(ver)+'_/' \n",
    "savefig = './analysis_figs'\n",
    "figname = 'tc_24'\n",
    "\n",
    "############ Plotting Commands ########\n",
    "figx=8\n",
    "figy=8\n",
    "\n",
    "labels = [r'QKF(True $\\Phi)$', r'QKF(AKF $\\Phi$)', r'']\n",
    "color = [COLOURDICT['QKF'], COLOURDICT['AKF'], COLOURDICT['TRUTH']]\n",
    "figstyl = [STYLEDICT['QKF'], STYLEDICT['AKF'], '-']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#### LOW Q REGIME - AR(2) PROCESS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to satisfy the following constraints \n",
    "\n",
    "For stationarity:\n",
    "    (a) ph1 + ph2 < 1\n",
    "    (b) ph1 - ph2 < 1\n",
    "    (c) phi2| < 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ######## Covariance Stationary, MS Ergoic AR(2) Process#######\n",
    "# # Stationary ARMA: http://matthieustigler.github.io/Lectures/Lect2ARMA.pdf\n",
    "\n",
    "# ar1 = -0.02# \n",
    "# ar2 = +0.968\n",
    "# q_regime.append(np.asarray([ar1, ar2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### HIGH Q REGIME - AR(q) PROCESS USING LEARNED LSF WEIGHTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We want to load a high order AR(q) model where we know that underlyign truth is stationary.\n",
    "\n",
    "from data_tools.load_raw_cluster_data import LoadExperiment\n",
    "\n",
    "test_case = 24\n",
    "variation_scan = [1, 2, 4, 7]\n",
    "\n",
    "for idx_var in variation_scan:\n",
    "    experiment = LoadExperiment(24, idx_var, \n",
    "                                LKFFB_load ='No',\n",
    "                                LSF_load='No',\n",
    "                                AKF_load='Yes', \n",
    "                                AKF_path=datapath,\n",
    "                                GPRP_load='No')\n",
    "\n",
    "    # We will now gradually move into the high q regime by considering the following weights:\n",
    "    q_regime.append(experiment.AKF_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Noise Parameters\n",
    "\n",
    "In order to generate our true process, we will keep the following process noise and measurement noise parameters the same, and we will feed the true values into QIF to side step auto-tuning of parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "######## True Process Noise Strength\n",
    "true_oe = 0.1**2\n",
    "######## True Msmt Noise Strength\n",
    "true_rk = 0.1**2\n",
    "####"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set up of Algorithm Parameters (QKF, LSF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###### Number of data points and initial points to exclude (burnin) #####\n",
    "num = 2050\n",
    "burn_in = 500\n",
    "\n",
    "###### AR Process Initialisation #####\n",
    "# we need phases to accumulate from 0 to pi. So our process is no longer mean zero.\n",
    "mean_noise = 0.5*np.pi\n",
    "\n",
    "###### Bayes Risk Runs ######\n",
    "runs = 50\n",
    "\n",
    "########### LSF ##############\n",
    "pick_alpha=0.1\n",
    "n_predict = 50\n",
    "n_train=num-n_predict\n",
    "num_of_iterGD = 50\n",
    "\n",
    "########### KF ##############\n",
    "p0init = 1000 # set same as AKF /LSF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initial Condition , Truth and Data Set Generation with Scaling "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from scipy.signal import periodogram\n",
    "def autocorr(x):\n",
    "    result = np.correlate(x, x, mode='full')\n",
    "    return result[result.size/2:]\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(autocorr(noisy_z_), '-')\n",
    "plt.plot(autocorr(true_x - mean_noise), ':')\n",
    "plt.show()\n",
    "plt.figure()\n",
    "freq, amp = periodogram(noisy_z_)\n",
    "plt.plot(freq, amp, ':')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "plt.figure(figsize=(figx*2,figy*2))\n",
    "plt.subplot(2,2,1)\n",
    "plt.title('True State X (Detuning) with Initial Burnin Disgarded')\n",
    "plt.plot(range(order), x_init + mean_noise, 'ro') \n",
    "plt.plot(true_x)\n",
    "plt.axhline(y=np.pi, c='r')\n",
    "plt.axhline(y=0, c='r')\n",
    "plt.axvline(x=100, c = 'k')\n",
    "#plt.ylim([-2*np.pi, 2*np.pi])\n",
    "\n",
    "plt.subplot(2,2,2)\n",
    "plt.title('Noisy State Z(x) (Probability)')\n",
    "plt.plot(noisy_z_ + 0.5, '--' )\n",
    "plt.plot(projected_msmt(noisy_z_ ), 'o')\n",
    "#plt.ylim([-0.1, 1.1])\n",
    "\n",
    "plt.subplot(2,2,3)\n",
    "plt.title('Distribution of X - 1/2 pi')\n",
    "plt.hist(true_x - mean_noise)\n",
    "\n",
    "plt.subplot(2,2,4)\n",
    "plt.title('Distribution of Z')\n",
    "plt.hist(noisy_z_)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from scipy.signal import periodogram\n",
    "\n",
    "def autocorr(x):\n",
    "    result = np.correlate(x, x, mode='full')\n",
    "    return result[result.size/2:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Run 100 times; with QKF using true dynamics and LSF learned dynamics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for idx_q_regime in xrange(len(q_regime)):\n",
    "    \n",
    "    \n",
    "\n",
    "    # Pick the AR(q) regime of coefficients\n",
    "    true_weights = q_regime[idx_q_regime]\n",
    "    order = true_weights.shape[0]\n",
    "    n_start_at=n_train - order + 1\n",
    "    \n",
    "    print(\"The true weights are of order: \", order)\n",
    "\n",
    "    # Set random initial conditions. These apply to the entire experiment.\n",
    "    x_init = np.random.uniform(low=-0.5*np.pi, high=0.5*np.pi, size=order)\n",
    "\n",
    "    # We store the residuals and the x_hat \n",
    "    x_true_dynamics = np.zeros((runs, order, num))\n",
    "    x_LSF_dynamics = np.zeros((runs, order, num))\n",
    "\n",
    "    gain_true_dynamics = np.zeros((runs, order, num))\n",
    "    gain_LSF_dynamics = np.zeros((runs, order, num))\n",
    "\n",
    "    truths_ = np.zeros((runs, num))\n",
    "    err_true_dynamics = np.zeros((runs, num))\n",
    "    err_LSF_dynamics = np.zeros((runs, num))\n",
    "\n",
    "\n",
    "    ######### Make an ensemble of QIF experiments ############\n",
    "\n",
    "    for idx_run in xrange(runs):\n",
    "\n",
    "        # Make truth for one run\n",
    "        true_x = generate_AR(x_init, num + burn_in, true_weights, true_oe)[burn_in:] + mean_noise \n",
    "        truths_[idx_run, :] = true_x # this is mean 0.5 pi\n",
    "        noisy_z_ = noisy_z(true_x, true_rk) # this is mean zero\n",
    "\n",
    "        # Find LSF weights using quantised msmts\n",
    "        measurements_train = projected_msmt(noisy_z_)\n",
    "        measurements_val = projected_msmt(noisy_z_) # true_x doesnt change\n",
    "        object_ = doLSF_forecast(measurements_train, measurements_val, pick_alpha, \n",
    "                           n_start_at, n_predict, order, \n",
    "                           steps_between_msmts=1, num_of_iterGD=num_of_iterGD)\n",
    "\n",
    "        # Generate validation dataset\n",
    "        y_signal = projected_msmt(noisy_z_)\n",
    "\n",
    "        # Run QIF using True Dynamics \n",
    "        predictions, W, x_hat, P_hat, err_true_dynamics[idx_run, :] = qif('truedynamics', y_signal, \n",
    "                                                                          true_weights, true_oe, true_rk, \n",
    "                                                                          n_train=n_train, \n",
    "                                                                          n_testbefore=n_predict, \n",
    "                                                                          n_predict=n_predict, \n",
    "                                                                          p0=p0init, skip_msmts=1,  save='No')\n",
    "        # Run QIF using LSF Learned Dynamics \n",
    "        predictions_l, W_l, x_hat_l, P_hat_l, err_LSF_dynamics[idx_run, :] = qif('lsfdynamics', y_signal, \n",
    "                                                                                 object_[1][1].ravel() , \n",
    "                                                                                 true_oe, true_rk, \n",
    "                                                                                 n_train=n_train, \n",
    "                                                                                 n_testbefore=n_predict, \n",
    "                                                                                 n_predict=n_predict, \n",
    "                                                                                 p0=p0init, \n",
    "                                                                                 skip_msmts=1, save='No')\n",
    "        # Store run for this experiment\n",
    "        x_true_dynamics[idx_run, :, :] = x_hat[:,0,:]\n",
    "        x_LSF_dynamics[idx_run, :, :] = x_hat_l[:,0,:]\n",
    "\n",
    "        gain_true_dynamics[idx_run, :, :] = W[:,0,:]\n",
    "        gain_LSF_dynamics[idx_run, :, :] = W_l[:,0,:]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ######### Calculate Bayes Risk with respect to z for each experiment ############\n",
    "\n",
    "    z_true_dynamics = np.asarray([noisy_z(sequence, 0.) for sequence in x_true_dynamics[:, 0, 0:num]])\n",
    "    z_LSF_dynamics = np.asarray([noisy_z(sequence, 0.) for sequence in x_LSF_dynamics[:, 0, 0:num]])\n",
    "\n",
    "    ######### Calculate Bayes Risk for predicting mean z = 0.5cos(f_n) == 0  ############\n",
    "    truths_z = np.asarray([noisy_z(sequence, 0.) for sequence in truths_[:, 0:num]])\n",
    "    predict_one = np.mean((truths_z)**2, axis=0)\n",
    "\n",
    "    ######### Normalise Bayes Risk  ############\n",
    "\n",
    "    norm_z_states_ = [(qkf_state_err(z_true_dynamics[:, :], truths_z)) / predict_one, \n",
    "                      (qkf_state_err(z_LSF_dynamics[:, :], truths_z)) / predict_one,\n",
    "                      predict_one / predict_one]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    ######### Plot the Experiment   ############\n",
    "\n",
    "    run = int(np.random.uniform(low=0, high = runs))\n",
    "\n",
    "    gs = gridspec.GridSpec(1, 6,\n",
    "                           left=0.21, right=0.95, \n",
    "                           top=0.9, bottom=0.16, \n",
    "                           wspace=0.55, hspace=0.2)\n",
    "\n",
    "\n",
    "    fig = plt.figure(figsize=(cm2inch(36),cm2inch(6)))\n",
    "\n",
    "    ax_2 = fig.add_subplot(gs[0, 0])# Bayes Risk wrt to z msmts [full]\n",
    "    ax_0 = fig.add_subplot(gs[0, 1]) # Prediction Risk only\n",
    "    ax_3 = fig.add_subplot(gs[0, 2]) # Single run likehood tracking\n",
    "    ax_1 = fig.add_subplot(gs[0, 3])# fig.add_axes([0.72, 0.22, 0.11, 0.09]) # Single run detuninng\n",
    "    ax_4 = fig.add_subplot(gs[0, 4])\n",
    "    ax_5 = fig.add_subplot(gs[0, 5])\n",
    "    \n",
    "    # Autocorrelation and periodgram from one run\n",
    "    \n",
    "    ax_4.plot(autocorr(truths_z[run,:]), '-')\n",
    "    ax_4.plot(autocorr(truths_[run,:] - mean_noise), ':')\n",
    "    freq, amp = periodogram(truths_z[run,:])\n",
    "    ax_5.plot(freq, amp, ':')\n",
    "    \n",
    "    # Single Run f_n\n",
    "\n",
    "    ax_1.plot(np.arange(-n_train, n_predict, 5), truths_[run, ::5], \n",
    "                 'x-', label='Single Run Dephasing', c=COLOURDICT['TRUTH'], lw=1, ms=1.)\n",
    "    ax_1.yaxis.set_major_formatter(FormatStrFormatter('%.0f'))\n",
    "    ax_1.minorticks_off\n",
    "    ax_1.set_xticks([-200, 0])\n",
    "\n",
    "\n",
    "    # Bayes Risk wrt to z msmts\n",
    "    for idx_algo in xrange(len(norm_z_states_)):   \n",
    "        ax_0.plot(np.arange(0, n_predict, 1), norm_z_states_[idx_algo][n_train: num], \n",
    "                 figstyl[idx_algo], label=labels[idx_algo], c=color[idx_algo],\n",
    "                  markeredgecolor=color[idx_algo], markerfacecolor=None, ms=1, alpha=1.0, lw=1)\n",
    "    ax_0.margins(0.2)\n",
    "    ax_0.set_yscale('log')\n",
    "    ax_0.set_xscale('log')\n",
    "    #ax_0.set_ylim([0.6,3.0])\n",
    "    ax_0.yaxis.set_major_locator(ticker.LogLocator(base=10, numticks=1))\n",
    "    ax_0.set_ylabel(r'$\\langle (f_n -\\hat{f_n})^2 \\rangle_D$')\n",
    "    ax_0.yaxis.set_major_formatter(FormatStrFormatter('%.0f'))\n",
    "    ax_0.yaxis.set_minor_formatter(FormatStrFormatter('%.0f'))\n",
    "\n",
    "    # Bayes Risk wrt to z msmts\n",
    "    for idx_algo in xrange(len(norm_z_states_)):   \n",
    "        ax_2.plot(np.arange(-n_train, n_predict, 1), norm_z_states_[idx_algo][0: ], \n",
    "                 figstyl[idx_algo], label=labels[idx_algo], c=color[idx_algo],\n",
    "                  markeredgecolor=color[idx_algo], markerfacecolor=None, ms=1, alpha=1.0, lw=1)\n",
    "    ax_2.margins(0.2)\n",
    "    ax_2.set_yscale('log')\n",
    "    ax_2.yaxis.set_major_locator(ticker.LogLocator(base=10, numticks=3))\n",
    "    ax_2.set_ylabel(r'$\\langle (f_n -\\hat{f_n})^2 \\rangle_D$')\n",
    "    ax_2.legend(loc=3,  fontsize=fsize, frameon=False, bbox_to_anchor=(-0.3, 1.02, 2.8, .102), \n",
    "                 ncol=3, mode=\"expand\", borderaxespad=0.)\n",
    "\n",
    "\n",
    "    # Single run likehood tracking\n",
    "    ax_3.set_ylabel(r'$P(d_n | f_n, \\tau, n)$')\n",
    "    ax_3.plot(np.arange(-n_train, n_predict, 1),z_true_dynamics[run,:] + 0.5, \n",
    "             figstyl[0], label=labels[0], c=color[0], markeredgecolor=color[0], markerfacecolor=None,  alpha=0.3, \n",
    "              ms=2, lw=1)\n",
    "    ax_3.plot(np.arange(-n_train, n_predict, 1),truths_z[run,:] + 0.5, \n",
    "             figstyl[2], label='Truth', c=color[2], markeredgecolor=color[2], markerfacecolor=None, alpha=1, ms=2, lw=1)\n",
    "    ax_3.plot(np.arange(-n_train, n_predict, 1),z_LSF_dynamics[run,:] + 0.5, \n",
    "             figstyl[1], label=labels[1], c=color[1], markeredgecolor=color[1], markerfacecolor=None,  \n",
    "              alpha=1, ms=1, lw=2)\n",
    "    ax_3.set_yticks([0, 1])\n",
    "\n",
    "    for ax in [ax_2, ax_0, ax_1, ax_3]: #ax_2\n",
    "        ax.tick_params(direction='in', which='both')\n",
    "        if ax != ax_0:\n",
    "            ax.set_xlim([-300, 50])\n",
    "        ax = set_font_sizes(ax, fsize, Fsize)\n",
    "\n",
    "    fig.savefig(savefig+figname+'_v_'+variation_scan[idx_q_regime]+'.svg', format='svg', dpi=400)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
