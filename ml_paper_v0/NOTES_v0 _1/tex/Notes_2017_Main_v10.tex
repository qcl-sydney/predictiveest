\section{Introduction} 

In predictive estimation, a dynamically evolving system is observed and any temporal correlations encoded in the observations are used to predict the future state of the system.  This generic problem is well studied in diverse fields such as engineering, finance, econometrics, meteorology, seismology, and physics [XXX REFERENCES], and is encapsulated in the control-theoretic literature as a form of filtering.  Applying these approaches to state estimation on qubits is complicated by a variety of factors: dominant among these is the violation of the assumption of linearity inherent in most filtering applications as qubit states are formally bilinear. The case of an idling, or freely evolving qubit subject to dephasing is more complicate still, as an a priori model of system evolution will not in general be available.

For classical systems, machine learning techniques have enabled state tracking, control, and forecasting for highly non-linear and noisy dynamical trajectories or complex measurement protocols (e.g. \cite{garcia2016optimal, bach2004learning, tatinati2013hybrid, hall2011reinforcement, hamilton2016ensemble}). These demonstrations move far beyond the simplified assumptions underlying many basic filtering tasks which assume simple linear dynamics and white (uncorrelated) noise processes. For instance, so-called particle-based Bayesian frameworks (e.g. particle filtering, unscented or sigma-point filtering) allow state estimation and tracking in the presence of nonlinearities in system dynamics or measurement protocols \cite{candy2016bayesian}.  Further extensions approach the needs of a stochastically evolving system; recently, an ensemble of so-called unscented Kalman filters (the name is derived from a mathematical transformation employed therein) demonstrated state estimation and forward predictions for chaotic, non-linear systems in the absence of a prescribed model~\cite{hamilton2016ensemble}. For non-chaotic, multi-component stationary random signals, other algorithmic approaches have been particularly useful for tracking instantaneous frequency and phase information, enabling short-run forecasting~\cite{boashash1992estimating2, ji2016gradient}.  
%and instead used nearest neighbour strategies between `particles' to model dynamics
%For sophisticated predictive estimation problems, machine learning tools offer unique opportunities to develop predictors which more accurately estimate future system evolution and/or to leverage computational resources in predictor optimization based on large datasets. 

In the field of quantum control work has begun to incorporate the additional challenges faced when considering state estimation on qubits, notably quantum state collapse under projective measurement.  Under such circumstances, in which the measurement backaction strongly influences the quantum state (in contrast with the classical case), it is not straightforward to extend machine learning predictive estimation techniques.  Work to date has approached the analysis of projective measurement records on qubits as pattern recognition or image reconstruction problems, for example, in characterising the initial or final state of quantum system (e.g. \cite{struchalin2016experimental, sergeevich2011characterization, mahler2013adaptive}) or reconstructing the historical evolution of a quantum system based on large measurement records (e.g. \cite{stenberg2016characterization, shabani2011efficient, shen2014reconstructing, de2016estimation, tan2015prediction, huang2017neural}). In adaptive or sequential Bayesian learning applications, a projective measurement protocol may be designed or adaptively manipulated to efficiently yield noise-filtered information about a quantum system (e.g. \cite{bonato2016optimized, wiebe2015bayesian}). 

The demonstrations above typically assume the object of interest is either static, or evolves in a manner which is dynamically uncorrelated in time (white) as measurement protocols are repeated. This simplifying assumption falls well short of typical laboratory based experiments where noise processes are frequently correlated in time, but evolution may occur rapidly relative to a measurement protocol.  Hence, the canonical real-time tracking and prediction problem in classical applications - where a non-linear, stochastic trajectory of a system is tracked using noisy measurements and short-run forecasts are made - is under-explored for quantum systems with projective measurements.

In this manuscript, we develop and explore a broad class of predictive estimation algorithms allowing us to track a qubit state undergoing \emph{stochastic but temporally correlated} evolution using a record of projective measurements, and forecast its future evolution. Our approaches employ machine learning algorithms to extract temporal correlations from the measurement record and use this information to build an effective dynamical model of the system's evolution.  We design a deterministic protocol to correlate Markovian processes such that a certain general class of non-Markovian dynamics can be approximately tracked without violating assumptions of a machine learning protocol, based on the theoretically accessible and computationally efficient frameworks of Kalman Filtering (KF) and Gaussian Process Regression (GPR).  Both frameworks provide a mechanism by which temporal correlations (equally, dynamics) are encoded into an algorithm's structure such that projection of datasets onto this structure enables meaningful learning, white noise filtering, and forward prediction.  We perform numerical simulations to test the effectiveness of these algorithms in maximizing the prediction horizon under various conditions; our study quantifies the role of the measurement sampling rate relative to the noise dynamics in defining the prediction horizon.  Simulations incorporate a variety of measurement models, including pre-processed data yielding a continuous measurement outcome and discretized outcomes commonly associated with projective measurement on qubits.   We find that in most circumstances an autoregressive Kalman framework yields the best perfromance, providing model-robust forward prediction horizons and effective filtering of measurement noise.  Finally, we demonstrate that GPR protocols, while effective for the problem of filtering (fitting) a measurement record, are incapable of performing real-time forward prediction in time.  

The general data sets available to an experimentalist implementing repeated projective measurements on a qubit take the form of a sequence of binary data, representing the qubit state at the conclusion of a single measurement.  Under slowly drifting, non-Markovian environmental dephasing noise, the probability of obtaining a particular measurement outcome inherits the properties of the noise Hamiltonian inducing qubit state evolution. The process of repeated projective measurement and state reset effectively discretises a continous-time random dephasing process into a sequence of \textit{stochastic but temporally correlated} qubit phases which are mapped to binary outcomes in the nonlinear measurement process.

Our overall objective is to identify and test appropriate machine learning frameworks, firstly, to track and predict non-Markovian qubit-state evolution, and secondly, to accommodate the specific non-linear measurement models inherent to qubit projective measurement. In standard Bayesian learning protocols, the output of Bayesian analysis at one instant of time is a probability distribution describing best possible knowledge of a true current state of a system. Typically, this knowledge is propagated in time using a theoretically known transition probability distribution which encodes, in signal processing language, time-domain (stochastic) `dynamics' for the true state. An analytically simple transition probability distribution is widely used for resampling procedures in particle-based methods and used for marginalisation procedures in sequential Bayesian methods \cite{candy2016bayesian} under the Markov approximation.  For such temporally uncorrelated processes, the true state of the system one discrete timestep forward is conditioned only on the current state of the system: \emph{i.e.} it does not depend on the system's history.   In our application, considerable complexity is introduced as the Markov condition is immediately violated. One may in principle design an appropriate transition probability distribution such that increasing non-Markovianity would contribute the increasing dimensionality of the problem as the `one-step ahead' state is conditioned on a increasing set of past states; this is an active area of research in classical applications (e.g  \cite{jacob2017bayesian}).  

In what follows, we describe in detail the physical setting for our problem in~\cref{sec:main:PhysicalSetting} and explain how this leads to a specific choice of algorithm which may be deployed for the task of tracking non-Markovian state dynamics in the absence of a dynamical model for system evolution.  We provide an overview of the central GPR and KF frameworks in \cref{sec:main:OverviewofPredictive Methodologies}, and we specify a series of algorithms under consideration in this paper tailored to different measurement processes. For pre-processed measurement records, we consider four algorithmic approaches: a Least Squares Filter (LSF) from \cite{mavadia2017}; an Autoregressive Kalman Filter (AKF); a so-called Liska Kalman Filter from \cite{livska2007} adapted for a Fixed oscillator Basis (LKFFB); and a suitably designed GPR learning protocol. For binary measurement outcomes, we extend the AKF to a Quantised Kalman Filter (QKF). In \cref{sec:main:Optimisation}, we present optimisation procedures for tuning all algorithms. Numerical investigations of algorithmic performance are presented in \cref{sec:main:Performance} and a comparative analysis of all algorithms is provided in \cref{sec:main:discussion}. 


\iffalse
These measurement outcomes provide discrete-time information about the \emph{stochastic but temporally correlated} evolution of a qubit's phase degree of freedom under a dephasing Hamiltonian. 

These numerical experiments investigate whether theoretical convergence occurs on timescales which enable meaningful qubit state predictions, where timescales are defined relative to sampling rates and properties of `true' (engineered) dephasing noise. 

 Using pre-processed measurements, we design a KF algorithm and a GPR algorithm to track general qubit dynamics using an oscillator approach. 
 
 In our study we survey a variety of algorithmic structures, constrasting oscillator-based approaches against those constructed via consideration of autoregressive dynamics. 
 
 We use machine learning protocols and simulated measurements to train algorithms such that we can track and predict the qubit state trajectory for a \textit{single realisation} of non-Markovian dephasing noise engineered from arbitrary power spectral densities.
  
  If each measurment outcome is effectively represented by a biased coin flip, then in our application the bias on the coin changes stochastically under dephasing noise. Further, a coin-flip (projective measurement) . These phases govern the superposition of 0 and 1 qubit states prior to measurement and hence they affect the probability of a seeing a 0 or 1 qubit state. 
 
 We use machine learning algorithms to extract temporal correlations from measurements and forecast the qubit state. The performance benchmark of an algorithm is to maximise the forecast period where its qubit state predictions are better than predicting the mean behaviour of the qubit under dephasing noise. We test our algorithms in numerical experiments representing realistic operating environments encountered in a laboratory. Our analysis considers two important types of measurement records, such that (a) single shot qubit outcomes are pre-processed before being given to an 
As an alternative approach, 

 Kalman Filtering (KF) and Gaussian Process Regression (GPR) are both examples of well established Bayesian approaches for tracking stochastic, non-linear true trajectories with Gaussian Markov noise inputs. Both KF and GPR represent mechanisms by which temporal correlations (equally, dynamics) are encoded into an algorithm's structure such that projection of datasets onto this structure enables meaningful learning, white noise filtering and forward prediction.  KF represents a recursive learning technique that easily lends itself to real time, adaptive filtering and control protocols. The wide-scale success of KF frameworks is based on well established extensions to non-linear, non-Gaussian regimes \cite{grewal2001theory}. GPR represents a batch learning algorithm with immense flexibility for tracking non-linear stochastic state dynamics, but tolerates only a linear measurement action \cite{rasmussen2005gaussian}. Both  KF and GPR allow us to approximately track non-Markovian stochastic dynamics, and additionally, a Kalman framework allows us to incorporate non-linear measurement models.

We simulate the use of suitably modified KF and GPR algorithms for real-time qubit state tracking and short-run predictions in realistic operating environments. It can be shown that for a certain class of true stochastic qubit state trajectories, a general representation using a collection of oscillators or using so-called `autoregressive' processes of finite order are guaranteed to converge to the true, unknown trajectory \cite{karlin2012first}.

\fi



\section{Physical Setting \label{sec:main:PhysicalSetting}}  
\label{sec:main:1} 


\begin{figure}[h!]
    \includegraphics[scale=1]{Predive_control_Fig_overview_17_one} 
    \caption{ \label{fig:main:Predive_control_Fig_overview_17_one} Physical Setting: In (a), we define the Hamiltonian for stochastic qubit dynamics under arbitrary environmental dephasing using a covariance stationary, non-Markovian detuning $\delta \omega(t)$ with an arbitrary power spectral density. A sequence of Ramsey experiments with fixed wait time $\tau$ yield single shot outcomes $\{ d_n \}$, with likelihood $Pr(d_n|\state_n, \tau,n)$,  conditioned on a mean-square ergodic sequence of true phases, $\{ f_n\}$, with $n \in [-N_T, 0]$ indexing time during data collection. Our objective is to maximise forward time $n \in [0, N_P]$ for which an algorithm uses measurement data to predict a future qubit state and incurs a lower Bayes prediction risk relative to predicting the mean value of the dephasing noise [dark gray shaded]. In (b), single shot outcomes are processed to yield noisy accumulated phase estimates, $\{ y_n\}$, corrupted by measurement noise $\{v_n\}$. The choice of $\{d_n\}$ or $\{y_n\}$ as datasets for predictive estimation corresponds to non-linear or linear measurement records in (b) and (c).}
\end{figure} 


 
Our physical setting considers a sequence of projective measurements performed on a qubit. Each projective measurement yields a 0 or 1 outcome representing the state of the qubit. The qubit is then reset, and the exact procedure is repeated. By considering a qubit state initialized in a superposition of the measurement ($\op{z}$) basis stances we gain access to a direct probe of qubit phase evolution.  If, for instance, no dephasing is present, then the probability of obtaining a binary outcome remains static in time as sequential qubit measurements are performed. If slowly drifting environmental dephasing is present, then the probability of obtaining a given binary outcome also drifts stochastically. In essence, we are using a qubit to probe dephasing noise and our procedure encodes a continuous time non-Markovian dephasing process into time-stamped, discrete binary samples through the nonlinear projective measurement, carrying the underlying correlations in the noise.  It is this series of measurements which we seek to process in our algorithmic approaches to qubit state tracking and prediction. 

Formally, an arbitrary environmental dephasing process manifests as time-dependent stochastic detuning, $\delta \omega (t)$, between the qubit frequency and the system master clock. This detuning is an experimentally measurable quantity in a Ramsey protocol, as shown schematically in Fig.~\ref{fig:main:Predive_control_Fig_overview_17_one} (a). A non-zero detuning over measurement period $\tau$ (starting from $t=0$) induces a stochastic relative phase accumulation (in the rotating frame) for a qubit superposition state as $\left|0\right\rangle+e^{-i\state(0, \tau)}\left|1\right\rangle$ between qubit basis states.  The accumulated $\state(0, \tau)$ at the end of a single Ramsey experiment is mapped to a probability of obtaining a particular outcome in the measurement basis via the form of the Ramsey sequence.  

In a sequence of $n$ Ramsey measurements spaced $\Delta t$ apart with a fixed wait time, $\tau$, the change in the statistics of measured outcomes over this measurement record depends solely on the dephasing  $\delta \omega(t)$.   We assume that the measurement action over $\tau$ is much faster than the temporal dynamics of the dephasing process, and $\Delta t \gtrsim \tau$. The resulting measurement record is a set of binary outcomes,  $\{d_n\}$, determined probabalitistically from $n$ true stochastic qubit phases, $\state := \{\state_n\}$. Here the accumulated phase in each Ramsey experiment, $ \state(n \Delta t, n\Delta t + \tau) \equiv \int_{n \Delta t}^{n \Delta t +\tau} \delta \omega(t') dt'$ and we use the shorthand $\state(n \Delta t , n\Delta t + \tau) \equiv \state_n$.  We define the statistical likelihood for observing a single shot, $d_n$, using Born's rule \cite{ferrie2013}:

\begin{align}
Pr(d_n | \state_n, \tau, n \Delta t) &= \begin{cases} \cos(\frac{\state(n \Delta t, n\Delta t + \tau)}{2})^2 \quad \text{for $d=1$} \\   \sin(\frac{\state(n \Delta t, n\Delta t + \tau)}{2})^2  \quad \text{for $ d=0$} \end{cases} \label{eqn:main:likelihood}
\end{align}
The notation $Pr(d_n | \state_n, \tau, n \Delta t)$ refers to the conditional probability of obtaining measurement outcome $d_n$ given a true stochastic phase, $\state_n$, accumulated over $\tau$, beginning at time $t = n \Delta t$. In the noiseless case, $Pr(d=1| f, \tau) = 1, \quad \forall n $, such that a qubit can be manipulated perfectly in the absence of net phase accumulation due to environmental dephasing. Following a single measurement the qubit state is reset, but the dephasing noise correlations manifest again through Born's rule to yield another random value for the bias at timestep $n+1$. %This procedure discretises $\delta \omega(t)$ into a random process, $\state$, governing qubit dynamics. 

The action of measurement, $h(\cdot)$, given $Pr(d_n | \state_n, \tau, n \Delta t)$, is depicted in Fig.~\ref{fig:main:Predive_control_Fig_overview_17_one}(b-c).  We begin by describing, in panel (b), a ``raw'' non-linear measurement record, $\{ d_n\}$.  Here each $d_n$ [black dots] corresponds to a single projective measurement on a qubit yielding a binary outcome. The sequence $\{ d_n\}$ can be treated as a sequence of biased coin flips, where the underlying bias of the coin is a non-Markovian, discrete-time process and the value of the bias is given by \cref{eqn:main:likelihood} at each $n$. The non-linearity of the measurement, $h(\cdot)$, is defined with respect to $\state$ where \cref{eqn:main:likelihood} is interpreted as a non-linear measurement action on $\state$ for Bayesian learning frameworks.

This data series is contrasted with a linear measurement record, $\{ y_n\}$, depicted in Fig.~\ref{fig:main:Predive_control_Fig_overview_17_one}(c), and fed to learning algorithms.  Each value $y_n$ is derived from the sum of a true qubit phase, $\state_n$, and Gaussian white measurement noise, $v_n$.  The sequence $\{ y_n\}$ is generated by pre-processing raw binary measurements, $\{ d_n\}$; this refers to averaging measurements on timescale $\sim\tau$ much faster than drift of $\delta \omega (t)$. Pre-processing comprises a range of experimental techniques to extract $\{ y_n\}$ from $\{ d_n\}$. In the most common case, one may perform $M$ runs of the experiment over which $\delta \omega (t)$ is approximately constant under the slow drift assumption, giving an estimate of  $\state_n$ at $t = n \Delta t $ using a Bayesian scheme or Fourier analysis. A more complex scheme which relaxes the slow drift assumption relative to $\tau$, involves the use of low-pass or decimation filtering on a sequence $\{ d_n\}$  to yield $\hat{Pr}(d_n | \state_n, \tau, n\Delta t)$, from which accumulated phase corrupted by measurement noise, $\{ y_n\}$, can be obtained from \cref{eqn:main:likelihood} (see Appendices). 

We impose properties on environmental dephasing such that our theoretical designs can enable meaningful predictions. We assume dephasing is non-Markovian, covariance stationary and mean-square ergodic.  That is, a single realisation of the process $\state$ is drawn from a power spectral density of arbitrary, but non-Markovian form. We further assume that $\state$ is a Gaussian process and the separation of timescales between measurement protocols and dephasing dynamics articulated above are met.

Given these conditions, our task is to build a dynamical model to approximately track $\state$ over past measurements ($n<0$), and enable qubit state predictions in future times($n>0$).  This prediction is represented by the red line in Fig.~\ref{fig:main:Predive_control_Fig_overview_17_one}(b-c), and differs from the truth by the estimation (prediction) risk for past (future) times as indicated by shading.  We represent our estimate of $\state$ for all times using a hat in both the linear and nonlinear measurement models.  The major challenge we face in developing this estimate, $\hat{\state}$ (equivalently $\hat{Pr}(d_n | \state_n, \tau, n\Delta t)$), is that for a qubit evolving under stochastic dephasing (true state given by grey solid line in Fig.~\ref{fig:main:Predive_control_Fig_overview_17_one}(b-c)), we have no apriori dynamical model for the underlying evolution of $\state$.  In the next section, we define the theoretical structure of KF and GPR algorithms which allow us to build that dynamical model directly from the historical measurement record. 




\section{Overview of Predictive Methodologies \label{sec:main:OverviewofPredictive Methodologies}}
% \begin{widetext}
\begin{figure*}[ht]
    \includegraphics[scale=1.]{Predive_control_Fig_overview_17_two} 
    \caption{ \label{fig:main:Predive_control_Fig_overview_17_two} Predictive Methodologies: (a) In GPR, a prior  distribution over true phase sequences $Pr(\state), \state \equiv \{ \state_n \}$ is constrained by a linear Bayesian likelihood of observed data, $\{ y_n\}$. The prior encodes dephasing noise correlations by defining covariance relations for the $n_1, n_2$-th time points using  $\Sigma_\state^{n_1, n_2}$ and optimising over its free parameters during training. The moments of the resulting predictive distribution $Pr(\state^{(\star)}|y)$ are interpreted as pointwise predictions and their pointwise uncertainties when evaluated for $n>0$.  (b) In KF, the Kalman state and its variance correspond to moments of a Gaussian distribution propagated in time via $\Phi$, and filtered via the Kalman gain, $\gamma$ at timestep $n$. The design of $\Phi$ deterministically colors a white noise process $\{w_n \}$ and `encodes' an apriori structure for learning dephasing noise correlations. Prediction proceeds by propagating forwards with $\gamma_n=0, n>0$. Additive white Gaussian measurement noise $v_n$ corrupts all measurement records.}
\end{figure*}
% \end{widetext}

Our objective is to find a learning algorithm that maximises the forward prediction horizon for a given qubit data record.  To define this we must first quantify the quality of our state estimation procedure.  The fidelity of any underlying algorithm during state estimation and prediction, relative to the true state, is expressed by the mathematical quantity known as a Bayes Risk, where zero risk corresponds to perfect estimation. At each timestep, $n$, the Bayes risk is a mean square distance between truth, $\state$, and prediction, $\hat{\state}$, calculated over an ensemble of $M$ different realisations of truth $\state$ and noisy datasets $\mathcal{D}$:
\begin{align}
L_{BR}(n | I) & \equiv \langle(\state_n - \hat{\state}_n)^2 \rangle_{\state,\mathcal{D}} \label{eqn:main:sec:ap_opt_LossBR}
\end{align}
The notation $L_{BR}(n | I)$ expresses that the Bayes Risk value at $n$ is conditioned on $I$, a placeholder for free parameters in the design of the predictor, $\hat{\state}_n$. State estimation risk is Bayes Risk incurred during $n \in [-N_T, 0]$; prediction risk is the Bayes Risk incurred during $n \in [0, N_P]$. State estimation and prediction risk regions for one realisation of dephasing noise are shaded in Figs.~\ref{fig:main:Predive_control_Fig_overview_17_one}-\ref{Predive_control_Fig_overview_17_three}.  We therefore define the forward prediction horizon as the number of time steps for $ n \in [0, N_P]$ during which a predictive algorithm incurs a lower Bayes prediction risk than naively predicting $\hat{\state}_n \equiv \mu_f = 0 \quad \forall n$, the mean qubit behaviour under zero-mean dephasing noise. 

With this concept in mind, we introduce two general approaches for algorithmic learning relevant to the strictures of the problem we have introduced.  Our general approach is shared between all algorithms employed and is represented schematically for the KF and GPR in Fig.~\ref{fig:main:Predive_control_Fig_overview_17_two}. Stochastic qubit evolution is depicted for one realisation of $\state$ (grey line) given noisy linear measurements (black dots) corrupted by Gaussian white measurement noise $v_n$.  Our overall task is to produce an estimate, given by the red line, which minimizes risk for the prediction period.  Ideally both estimation risk and prediction risk are minimized simultaneously for well performing implementation.

Examining the insets in both panels of Fig.~\ref{fig:main:Predive_control_Fig_overview_17_two}), both frameworks start with a prior Gaussian distribution over qubit states (purple) that is constrained by the measurement record to yield a posterior Gaussian distribution of the qubit state (red). The prior captures assumptions about the qubit state before any data is seen and the posterior expresses our best knowledge of the qubit state under a Bayesian framework.  The posterior distribution in both KF and GPR is used to generate qubit state estimates and predictions (red solid line).  However the process by which this posterior is inferred differs significantly between the two methods; we provide an overview of the central features of these algorithms below. 
%For linear measurement records, $h(x) \mapsto Hx$ and $f \equiv Hx$ linking GPR and KF notation. 

The key feature of a Kalman filter is the recursive learning procedure shown in the inset to Fig.~\ref{fig:main:Predive_control_Fig_overview_17_two}(a). Our knowledge of the qubit state is summarised by the prior and a posterior Gaussian probability distributions and these are created and collapsed iteratively \emph{at each time step}. The mean of these distributions is the true Kalman state, $x$, and the covariance of these distributions, $P$, captures the uncertainty in our knowledge of $x$; together both define the normal distribution. The Kalman filter produces an \emph{estimate} of the state, $\hat{x}_{n}$ at each step through this recursive procedure taking into account two factors. First, the Kalman gain, $\gamma_n$, updates our knowledge of $(x_n, P_n)$ within each time step $n$ and serves as a weighting factor for incoming data, suitably transformed via the measurement action, $h(x_{n})$. Next, the dynamical model $\Phi_n$ propagates the state and covariance, $(x_n, P_n)$, to the next time step, such that the posterior moments at $n$ define the prior at $n+1$.  This iterative process occurs for each time step, building the estimate for the past measurements.  Beyond $n=0$ we perform predictions in the absence of further measurement data by simply propagating the dynamic model with the Kalman gain set to zero.  Full details of the KF algorithm appear below in Sec.~\ref{Subsec:KF}.

 In our application, we define the Kalman state, $x$, the dynamical model $\Phi$, and a measurement action $h(x)$ such that the Kalman Filtering framework can track a non-Markovian qubit state trajectory due to an arbitrary realisation of $\state$. In standard KF implementations, the sequence $\{x_n\}$, defines a ``hidden'' signal that cannot be observed, and the dynamic model $\Phi_n$ is known.  We deviate from these standard implementations such that our true Kalman state and its uncertainty, $(x, P)$, do not have a direct physical interpretation.  Kalman $x$ has no a priori deterministic component and corresponds to arbitrary power spectral densities describing $\state$. Hence, the role of the Kalman $x$ is to represent an abstract correlated process that, upon measurement, yields physically relevant quantities governing qubit dynamics.  Moreover a key challenge described in detail below is to construct an effective $\Phi_{n}$ from the measurement record.   
%Often, Kalman $x$ can represent a multi-component signal and while $x$ is driven by white noise, typical filtering implementations specify a deterministic component to the evolution of $x$ or provide a desired reference trajectory for the filter to follow. As an illustrative example, in a linear regime, a true qubit phase sequence $\state$ has a physical interpretation, but $x$ and $\Phi$ are abstract entities designed to yield a sequence $\{x_n\}$ such that upon noiseless measurement, we recover $\state \equiv Hx$. 

In contrast to the iterative approach taken in the KF, a GPR learning protocol illustrated schematically in Fig.~\ref{fig:main:Predive_control_Fig_overview_17_two}(b) selects \textit{a random process} to best describe overall dynamical behaviour of the qubit state under one realisation of $\state$. The key point is that sampling the prior or posterior distribution in GPR yields random realisations of discrete time \textit{sequences}, rather than individual random variables, and GPR considers the entire measurement record at once.  In a sense, it corresponds to a form of fitting over the entire data set.  The output of a GPR protocol is a predictive distribution which we can evaluate at an arbitrarily chosen sequence of $N^{(\star)}$ time labels, $\{ n^{(\star)} \}$, where we interpret the result as state estimation if $n^{(\star)} \leq 0$ and predictions if $n^{(\star)}>0$. Here, the ${}^{(\star)}$ denotes testing points, namely, that we are evaluating the predictive posterior distribution of a GPR protocol at desired time labels.

The process of building the posterior distribution is implemented using a Kernel, or basis, from which to construct the effective fit.  In standard GPR implementations, the correlation between any two observations depends only on the separation distance of the index of these observations, and correlations are captured in the covariance matrix, $\Sigma_\state$. Each element, $\Sigma_\state^{n_1, n_2}$, describes this correlation for observations at arbitrary timesteps indexed $n_1$ and $n_2$: this quantity is the given in a form set by the selected Kernel. 

In our application, the non-Markovian dynamics of $\state$ are not specified explicitly but are encoded in a general way through the choice of Kernel, prescribing how $\Sigma_\state^{n_1, n_2}$ should be calculated. The Fourier transform of the kernel represents a power spectral density in Fourier space. A general design of $\Sigma_\state^{n_1, n_2}$ allows one to probe arbitrary stochastic dynamics and equivalently, explore arbitrary regions in the Fourier domain. For example, Gaussian kernels (RBF) and mixtures of Gaussian kernels (RQ) capture the continuity assumption that correlations die out as separation distances increase. We choose to employ an infinite basis of oscillators implemented by the so-called periodic kernel to enable us to represent arbitrary power spectral densities for $\state$.  Prediction occurs simply by extending the GPR fit beyond $n=0$.

%We define this as the number of time steps beyond the measurement record for which predictions of the qubit state are better than naively predicting the average behaviour of the qubit under dephasing.
In the following subsections we provide details of the specific classes of learning algorithm employed here with an eye towards evaluating their predictive performance on qubit-measurement records.  We introduce a series of KF algorithms capable of handling both linear and non-linear measurement records, and restrict our analysis of GPR to linear measurement records. 



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{ Kalman Filtering (KF)}\label{Subsec:KF}

%A Kalman Filter recursively tracks the stochastic evolution of a hidden true state. An incoming stream of unreliable (noisy) observations are fed to a Kalman Filter, and the objective of the Kalman Filter is to recursively improve its estimate of the true state at any time, $n\Delta t$, given the past $n$ measurements. 
In order for a Kalman Filter to track a stochastically evolving qubit state in our application, the hidden true Kalman state at timestep $n$, $x_n$, must mimic stochastic dynamics of a qubit under environmental dephasing. We propagate the hidden state $x_n$ according to a dynamical model $\Phi_n$ corrupted by Gaussian white process noise, $w_n$.  
\begin{align}
x_n & = \Phi_n x_{n-1} + \Gamma_n w_n \label{eqn:KF:dynamics} \\
w_n & \sim \mathcal{N}(0, \sigma^2) \quad \forall n 
\end{align}
Process noise has no physical meaning in our application - $w_n$ is shaped by $\Gamma_n$ and deterministically colored by the dynamical model $\Phi_n$ to yield a non-Markovian $x_n$ representing qubit dynamics under generalised environmental dephasing.  WHAT CAN BE SAID SUCCINCTLY ABOUT $\Gamma_n$?

We measure $x_n$ using an ideal measurement protocol, $h(x_n)$, and incur additional Gaussian white measurement noise $v_n$ with scalar covariance strength $R$, yielding scalar noisy observations $y_n$:
\begin{align}
y_n &= z_n + v_n \\
z_n & \equiv  h(x_n) \\
v_n & \sim \mathcal{N}(0, R) \quad \forall n
\end{align}
The measurement procedure, $h(x_n)$, can be linear or non-linear, allowing us to explore both regimes in our physical application.

With appropriate definitions, the Kalman equations below specify all Kalman algorithms in this paper. At each time step, $n$, we denote estimates of the moments of the prior and posterior distributions (equivalently, estimates of the true Kalman state) with $(\amx{n}, \amp{n})$ and $(\apx{n}, \app{n})$ respectively. The Kalman update equations take a generic form (c.f.~\cite{grewal2001theory}) :

\begin{align}
\amx{n} & = \Phi_{n-1} \apx{n-1} \label{eqn:main:KF:dynamic_x}\\ 
Q_{n-1} & = \sigma^2 \Gamma_{n-1}\Gamma_{n-1}^T  \label{eqn:main:KF:Q}\\
\amp{n}&= \Phi_{n-1} \app{n-1} \Phi_{n-1}^T + Q_{n-1} \label{eqn:main:KF:dynamic_P}\\
\gamma_n &= \amp{n} H_n^T(H_n\amp{n}H_n^T + R_n)^{-1} \label{eqn:main:KF:gain}\\
\hat{y}_n(-) & = h(\amx{n}) \label{eqn:main:KF:step_ahead}\\
\apx{n} &= \amx{n} + \gamma_n (y_n - \hat{y}_n(-)) \label{eqn:main:KF:bayesian_x}\\
\app{n} &= \left[1  - \gamma_n H_n \right] \amp{n} \label{eqn:main:KF:bayesian_p}
\end{align}
To reiterate formally, \cref{eqn:main:KF:dynamic_x} and \cref{eqn:main:KF:dynamic_P} bring the best state of knowledge from the previous time step into the current time step, $n$, as a prior distribution. Dynamical evolution is modified by features of process noise, as encoded in \cref{eqn:main:KF:Q}, and propagated in \cref{eqn:main:KF:dynamic_P}. The propagation of the moments of the apriori distribution, as outlined thus far, does not depend on the incoming measurement, $y_n$, but is determined entirely by the apriori (known) dynamical model, in our case $\Phi \equiv \Phi_n, \forall n$. 

The Kalman gain depends on the uncertainty in the true state, $\amp{n}$ and is modified by features of the measurement model, $H_n$, and measurement noise, $R\equiv R_n \forall n$. It serves as an effective weighting function for each incoming observation.  Before seeing any new measurement data, the filter predicts an observation $\hat{y}_n(-)$ corresponding to the best available knowledge at $n$ in \cref{eqn:main:KF:step_ahead}. This value is compared to the actual noisy measurement $y_n$ received at $n$, and the difference is used update our knowledge of the true state using \cref{eqn:main:KF:bayesian_x}. If measurement data is noisy and unreliable (high $R$), then $\gamma$ has a small or a null value, and the algorithm propagates Kalman state estimates according to the dynamical model and virtually ignores data. In particular, only the second terms in both \cref{eqn:main:KF:bayesian_x} and \cref{eqn:main:KF:bayesian_p} represent the Bayesian update of the moments of priori distribution ($(-)$ terms) to the posterior distribution ($(+)$ terms) at $n$. If $\gamma_n \equiv 0$, then the prior and posterior moments at any time step are exactly identical by \cref{eqn:main:KF:bayesian_x,eqn:main:KF:bayesian_p}, and only dynamical evolution occurs using \cref{eqn:main:KF:dynamic_x,eqn:main:KF:Q,eqn:main:KF:dynamic_P}.  This is the condition we employ when we seek to make forward predictions beyond a single timestep, and hence we set $\gamma \equiv 0$ during future prediction.

Since we do not have a known dynamical model $\Phi$ for describing stochastic qubit dynamics under $\state$, we will need to make design choices for  $\{ x, \Phi, h(x), \Gamma \}$  such that $\state$ can be approximately tracked. These design choices will completely specify algorithms introduced below and represent key findings with respect to our work in this manuscript. For a linear measurement record, $h(x) \mapsto Hx$ and we compare predictive performance for $\Phi$ modelling stochastic dynamics either via so-called `autoregressive' processes in the AKF, or via projection onto a collection of oscillators in the LKKFB.  In addition, we use the dynamics of AKF to define a Quantised Kalman filter (QKF) with a non-linear, quantised measurement model such that the filter can act directly on binary qubit outcomes. We provide the relevant details in sub-sections below. 
 


\subsubsection{Autoregressive Kalman Filter (AKF)}

The AKF is well-studied in classical engineering and control applications (\emph{c.f.}~\cite{moon2006real}) presenting opportunities to leverage existing engineering knowledge in developing quantum control strategies.  In our application this class of Kalman filter probes arbitrary, covariance stationary qubit dynamics such that the dynamic model is constructed as a weighted sum of $q$ past values driven by white noise {\em i.e.} an autoregressive process of order $q$, AR($q$). By Wold's decomposition, any zero mean covariance stationary process representing qubit dynamics has a representation in the mean-square limit by an autoregressive process of finite order.% $q_c$, AR($q_c$) where the ability to approximate arbitrary power spectral density for a covariance stationary process typically falls with model complexity, $c$ \cite{west1996bayesian}. We design the Kalman dynamical model, $\Phi$, such that the true Kalman state is AR($q$) process that approximately tracks the qubit state. 
The study of AR($q$) processes falls under a general class of techniques based on autoregressive moving average (ARMA) models in classical control engineering [XXX REFERENCE]. For high $q$ models in a typical time-series analysis, it is possible to decompose an AR($q$) into an ARMA model with a small number of parameters \cite{brockwell1996introduction, salzmann1991detection}. However, we retain a high $q$ model to probe arbitrary power spectral densities. Further, literature suggests employing a high $q$ is relatively easier than a full ARMA estimation problem and enables lower prediction errors \cite{wahlberg1989estimation,brockwell1996introduction}.

To construct the Kalman dynamical operator $\Phi$ for the AKF, we introduce a lag operator, $\mathcal{L}$, where each application of the lag operator retards a true state by one time step:
\begin{align}
\mathcal{L}^{q'}: f_n &\mapsto f_{n-q'}, \quad \forall q' \leq n \\
\Phi(\mathcal{L},q) & \equiv  1 - \phi_1 \mathcal{L} - \phi_2 \mathcal{L}^2 - ... - \phi_q \mathcal{L}^q 
\end{align}
Here, the set of $q$ coefficients $\{\phi_{q' \leq q}\}, q' = 1, ... , q $ are the set of autoregressive coefficients which specify the dynamical model. Hence, the true stochastic Kalman state dynamics are:
\begin{align}
\Phi(\mathcal{L},q) \state_n & = w_n \\ 
\implies \state_n & = \phi_1 \mathcal{L} \state_n + \phi_2 \mathcal{L}^2 \state_n + ... + \phi_q \mathcal{L}^q \state_n + w_n \\
 \state_n &= \phi_1 \state_{n-1} + \phi_2 \state_{n-2} + ... + \phi_q \state_{n-q} + w_n \label{eqn:main:ARprocess}
\end{align}
We thus see that the dynamical model is constructed as a weighted sum of time-retarded samples of $\state$, with weighting factors given by the autoregressive coefficients up to order (and hence time lag) $q$.  %Formally, \cref{eqn:main:ARprocess} is an AR($q$) process. 
For small $q < 3$, it is possible to extract simple conditions on the coefficients, $\{ \phi_{q' \leq q} \}$, that guarantee properties of $\state$, for example, that $\state$ is covariance stationary and mean square ergodic. In our application, we freely employ arbitrary-$q$ models via machine learning in order to improve our approximation of an arbitrary $\state$. Any AR($q$) process can be recast (non-uniquely) into state space form [XXX REFERENCE], and we define the AKF by the following substitutions into Kalman equations:
\begin{align}
x_n & \equiv  \begin{bmatrix} f_{n} \hdots f_{n-q+1} \end{bmatrix}^T \\
\Gamma_n w_n & \equiv \begin{bmatrix} w_{n} 0 \hdots 0 \end{bmatrix}^T \\
\Phi_{AKF} & \equiv 
\begin{bmatrix}
\phi_1 & \phi_2 & \hdots & \phi_{q-1} & \phi_q \\ 
1 & 0 & \hdots & 0 & 0 \\  
0 & 1 & \ddots & \vdots & \vdots \\ 
0 & 0 & \ddots & 0 & 0 \\ 
0 & 0 & \hdots & 1 & 0 
\end{bmatrix} \quad \forall n \label{eqn:akf_Phi} \\
H & \equiv \begin{bmatrix} 1\;\;0\;\;0\;\;0\hdots0 \end{bmatrix} \quad \forall n  
\end{align}
The matrix $\Phi_{AKF}$ is the dynamical model used to recursively propagate the unknown state during state estimation in the AKF, as represented schematically in the upper half of Fig.~\ref{Predive_control_Fig_overview_17_three}. In general, the $\{\phi_{q' \leq q}\}$ employed in $\Phi_{AKF}$ must be learned through an optimisation procedure using the measurement record, where the set of parameters to be optimised is $\{\phi_1, \hdots, \phi_q, \sigma^2, R \}$. This procedure yields the optimal configuration of the autoregressive Kalman filter, but at the computational cost of a $q+2$-dimensional Bayesian learning problem for arbitrarily large $q$.

The Least Squares Filter (LSF) in \cite{mavadia2017} considers a weighted sum of past measurements to predict the $i$-th step ahead measurement outcome. A gradient descent algorithm learns the weights, $\{\phi_{q' \leq q}\}$ for the previous $q$ past measurements, and a constant offset value for non-zero mean processes, to calculate the $i$-th step ahead prediction, $i \in [0, N_P]$. The set of $N_P$ LSF models, collectively, define the set of predicted qubit states under an LSF acting on a measurement record.

For $i=1$, equivalent to the single-step update employed in the Kalman filter, we assert that learned $\{\phi_{q' \leq q}\}$ in LSF effectively implements an AR($q$) process (we validate numerically in Sec.~\ref{sec:main:Performance}). Under this condition, and for zero-mean $w_n$, the LSF in \cite{mavadia2017} by definition searches for coefficients for the weighted linear sum of past $q$ measurements, as described in in \cref{eqn:main:ARprocess}. We use the parameters $\{\phi_{q' \leq q}\}$ learned in the LSF to define $\Phi_{AKF}$, therefore reducing the computational complexity of the remaining optimisation from ($(q+2)\to 2$)-dimensional for an AKF of order $q$. Since Kalman noise parameters ($\sigma^2, R$) are subsequently auto-tuned using a Bayes Risk optimisation procedure (see Sec.~\ref{sec:main:Optimisation}), we optimise over potential remaining model errors and measurement noise.  

\begin{figure} [tp]
    \includegraphics[scale=1]{Predive_control_Fig_overview_17_three_v2}
    \caption{\label{Predive_control_Fig_overview_17_three} Building the dynamical model, $\Phi$: All Kalman dynamical models, $\Phi$, are mean square approximations to qubit dynamics under arbitrary covariance stationary, non-Markovian, mean square ergodic $\state$. AKF/QKF: Kalman $\Phi$, implements a weighted sum of $q$ past measurements driven by process noise, $w$. We represent $\Phi$ using a lag operator, $\mathcal{L}^{q'}: \state_n \mapsto \state_{n-q'}$, and coefficients, $ \{ \phi_{q' \leq q} \}$ learned from LSF in \cite{mavadia2017}. This defines an autoregressive process of order $q$ and we use a high $q$ model to approximate any covariance stationary $\state$ [top]. LKFFB: Kalman $\Phi$ represents a collection of $J^{(B)}$ oscillators driven by process noise, $w$, where frequency of oscillators must span dephasing noise bandwidth. The instantaneous amplitude and phase of each basis oscillator can be derived from the Kalman state estimate $x^j_n$ at any $n$. Predictions combine learned amplitudes and phases for each basis oscillator and sum contributions over all $J^{(B)}$ [bottom].}
\end{figure}

In general, LSF performance improves as $q$ increases and a full characterisation of model-selection decisions for LSF are given in \cite{mavadia2017}. Defining an absolute value for the optimal $q$ is somewhat arbitrary as it is defined relative to the extent to which a true $\state$ is oversampled in the measurement routine. For all analyses presented here, we fix the ratio $q \Delta t = 0.1 [a.u.]$, where the experimental sampling rate is $1/\Delta t$ and $\{\phi_{q' \leq q}\}$ are identical in the AKF and LSF.   In practice this ensures numerical convergence of the LSF during training.
%For simplicity, we fix a high $q$ model for all numerical experiments considered in this manuscript such that they exhibit numerical convergence behaviour during LSF training. In particular, numerical convergence for LSF means an analysis of errors generated as a gradient descent optimiser is used to learn autoregressive coefficients. Our choice of high $q$ is such that (a) state estimation errors gradually reduce with the number of iterations during a gradient descent optimisation in LSF, and (b), we operate in regimes where net state estimation error at the \textit{end} of a gradient descent optimisation exhibits diminishing returns as $q$ is increased in the underlying LSF model. Implementation details of gradient descent optimisation for LSF are relegated to \cite{mavadia2017}. We numerically confirm that gains for finely tuning $q$ for both LSF and AKF are insignificant for comparisons made in this manuscript.

\subsubsection{Liska Kalman Filter with Fixed Basis (LKFFB)}
In LKFFB, we effectively perform a Fourier decomposition of the underlying $\state$ in order to build the dynamic model, $\Phi$, for the Kalman filter.   Here, we project our measurement record on $J^{(B)}$ oscillators with fixed frequency $\omega_{j}\equiv j\omega_0^{(B)}$ with $j$ an integer as $j = 1, \hdots, J^{(B)}\}$. The temporal resolution of the state tracking procedure is set by the maximum frequency in the selected basis.  The superscript $ ^{(B)}$ indicates Fourier domain information about an algorithmic basis, as opposed to information about the true (unknown) dephasing process.  The LKFFB allows instantaneous amplitude and phase tracking for each basis oscillator, directly enabling forward prediction from the learned dynamics.  The structure of this Kalman filter, referred to as the Liska Kalman Filter (LKF), was developed in \cite{livska2007}; adding a fixed basis in this application yields the Liska Kalman Filter with a Fixed Basis (LKFFB).

For our application, the true hidden Kalman state, $x$, is a collection of sub-states, $x^j$, for the $j^{th}$ oscillator. For clarity we remind that the superscript is used as an index rather than a power.  Each sub-state is labeled by a real and imaginary component which we represent in vector notation: 
\begin{align}
x_n & \equiv \begin{bmatrix} x^{1}_{n} \hdots x^{j}_{n} \hdots x^{J^{(B)}}_{n} \end{bmatrix} \\
A^j_{n} & \equiv \textrm{Re}(x^{j}_{n}) \\
B^j_{n} & \equiv \textrm{Im}(x^{j}_{n}) \\
x^j_n & \equiv \begin{bmatrix} A^j_{n} \\ B^j_{n}  \end{bmatrix}
\end{align} 
The algorithm tracks the real and imaginary parts of the Kalman sub-state simultaneously in order calculate the instantaneous amplitudes ($\norm{x^j_n}$) and phases ($\theta^{j}_{n}$)  for each Fourier component:
\begin{align}
\norm{x^j_n} & \equiv \sqrt{(A^j_{n})^2 + (B^j_{n})^2} \\
\theta^{j}_{n} & \equiv \tan{\frac{B^j_{n}}{A^j_{n}}}
\end{align}

The dynamical model for LKFFB is constructed as a stacked collection of independent oscillators. The sub-state dynamics match the formalism of a Markovian stochastic process defined on a circle for each basis frequency, $\omega_j$, as in Ref.~\cite{karlin2012first}. We stack $\Phi(j \omega_0^{(B)}\Delta t) $ for all $\omega_j$ along the diagonal to obtain the full dynamical matrix for $\Phi_n$:
\begin{align}
\Phi_{n} & \equiv \begin{bmatrix} 
\Phi(\omega_0^{(B)}\Delta t)\hdots 0  \\ 
 \hdots \Phi(j\omega_0^{(B)}\Delta t) \hdots \\
0 \hdots \Phi(J^{(B)} \omega_0^{(B)}\Delta t)  \end{bmatrix}\\ 
\Phi(j \omega_0^{(B)}\Delta t) &\equiv \begin{bmatrix} \cos(j \omega_0^{(B)}\Delta t) & -\sin(j \omega_0^{(B)}\Delta t) \\ \sin(j \omega_0^{(B)}\Delta t) & \cos(j \omega_0^{(B)}\Delta t) \\ \end{bmatrix} \label{eqn:ap_approxSP:LKFFB_Phi} 
\end{align}

We obtain a single estimate of the true hidden state by defining the measurement model, $H$, by concatenating $J^{(B)}$ copies of the row vector $[1\;\;0]$ :
\begin{align}
H & \equiv \begin{bmatrix} 1\;\;0 \hdots 1\;\;0 \hdots 1\;\;0 \end{bmatrix}
\end{align}
Here, the unity values of $H$ pick out and sum the Kalman estimate for the real components of $\state$ while ignoring the imaginary components, namely, we sum $A^{j}_{n}$ for all $J^{(B)}$ basis oscillators.

%We observe numerically that instantaneous amplitude and phase information for different basis components are resolved at different timescales while the filter is receiving an incoming stream of measurements (see Appendices). 
In \cite{livska2007}, a state dependent process noise shaping matrix is introduced to enable potentially non-stationary instantaneous amplitude tracking in LKKFB for each individual oscillator: 
\begin{align}
\Gamma_{n-1} &\equiv \Phi_{n-1}\frac{x_{n-1}}{\norm{x_{n-1}}}
\end{align}
For the scope of this manuscript, we retain the form of $\Gamma_{n}$ in our application even if true qubit dynamics are covariance stationary. As such, $\Gamma_{n}$ depends on the state estimates $x$. For this choice of $\Gamma_{n}$, we deviate from classical Kalman filters because recursive equations for $P$ cannot be propagated in the absence of measurement data. Consequently, Kalman gains cannot be pre-computed prior to experimental data collection. Details of gain pre-computation in classical Kalman filtering can be found in standard textbooks (e.g. \cite{grewal2001theory}).

There are two ways to conduct forward prediction for LKFFB and both are numerically equivalent for the choice of basis outlined in Appendices: (i) we set the Kalman gain to zero and recursively propagate using $\Phi$; (ii) we define a harmonic sum using the basis frequencies and learned $\{\norm{x^j_n}, \theta^{j}_{n} \}$.  This harmonic sum can be evaluated for all future time to yield forward predictions a single calculation. 





\subsubsection{Quantised Kalman Filter (QKF)}

In QKF, we implement a Kalman filter that acts directly discretised measurement outcomes $\{0,1\}$. To reiterate the discussion of  \cref{fig:main:Predive_control_Fig_overview_17_one}(a), this means that the measurement action in QKF must be non-linear and take as input quantised measurement data. This holds true irrespective of our dynamical model, $\Phi$.  In our application we set the dynamical model to be identical to that employed in the AKF, allowing isolation of the effect of the nonlinear measurement action.

With unified notation across AKF and QKF, we define a measurement model $h(x)$ and its Jacobian, $H$ as:
\begin{align}
z_n &  \equiv h(f_n) \equiv \frac{1}{2}\cos(\state_{n}) \\
% & \equiv h(x_n[0]) \\
\implies H_n &\equiv \frac{d h(\state_n)}{d\state_n} =  -\frac{1}{2}\sin(\state_{n})
\end{align}
During filtering, the QKF applies $h(x)$ to compute measurement residuals when updating the true Kalman state, $x$. The Jacobian is used to propagate the state variance estimate and to compute the Kalman gain. The linearisation of $h(x)$ by $H_n$ holds if errors during the filtering process remain small, including model errors in dynamical propagation. 

In this construction the entity $z$ is associated with an abstract `signal': a likelihood function for a single qubit measurement in \cref{eqn:main:likelihood}.  In our application, we track the correlated phase sequence $\state$ as our Kalman hidden state, $x$. Subsequently, we extract an estimate of the true bias, $z$, as an unnatural application of the Kalman measurement model.  The sequence $z$ is not observable, but can only be inferred over a large number of experimental runs. To complete the measurement action, we implement a biased coin flip within the QKF filter given $y$.  While the qubit provides measurement outcomes which are naturally quantised, we require a theoretical model, $\mathcal{Q}$, to generate quantised measurement outcomes with statistics that are consistent with Born's rule in order to propagate the dynamic Kalman filtering equations appropriately. In order to build this machinery we modify the procedure in \cite{karlsson2005} to encode $z$ using biased coin flips. Notationally, we represent a black-box quantiser, $\mathcal{Q}$, that gives only a $0$ or a $1$ outcome based on $y_n$:
\begin{align}
d_n &= \mathcal{Q}(y_n)\\
&=  \mathcal{Q}(h(\state_n) + v_n)
\end{align}
Therefore the stochastic changes in $\{ y_n\}$ are represented in the bias of a coin flip, subject to proper normalisation constraints as  
\begin{align}
Pr(d_n| y_n, \state_{n}, \tau) & \equiv \mathcal{B}(n_{\mathcal{B}}=1;p_{\mathcal{B}}= y_n + 0.5 ) \label{eqn:main:qkf:binomial}
\end{align}
which maintains $|y_n| \leq 0.5$ and \cref{eqn:main:qkf:binomial} defines a biased coin flip used in QKF.   The definitions of $\{ \mathcal{Q}, h(x_n), H_n \}$ in this subsection, and $\{x, \Phi, \Gamma\}$ from the AKF now completely specify the QKF algorithm for application to a discrete, single-shot measurement record as depicted in \cref{fig:main:Predive_control_Fig_overview_17_one} (a).  

%We note that the bias of a coin flip, namely, $ Pr(d_n|f_n, \tau, t) \propto z_n$, cannot be measured directly but only inferred in the frequentist sense for a large number of parallel runs, or in the Bayesian sense, by deconstructing the problem further using Bayes rule.

% If $z$ was a real signal, one could use \cite{karlsson2005,widrow1996} to encode $z$ into a binary sequence. This is a classical linear transformation where one discretises the amplitude of any signal by discretising the probability distribution of the underlying Gaussian errors generated from quantisation of a continuous amplitude value to its nearest allowed level. 

To conclude our introduction to the structure of the QKF, w comment briefly on the statistical description of the action of the coin-flip quantiser below such that the machinery outlined in \cite{karlsson2005} can be applied for future analysis. In particular, a binomial distribution parameterised by a random variable $y_n$ means that $\mathcal{Q}$ defines the likelihood of getting a $0$ or a $1$ after marginalising over all possible values of $y_n$.  
\begin{align}
\mathcal{Q}: & Pr(d_n | \state_{n}, \tau), \quad |y_n| \leq b = 0.5\\
& \equiv  \int (Pr(y_n | \state_{n}, \tau) * \mathcal{U}(b) ) Pr(d_n | y_n, \state_{n}, \tau) dy_n \\
\mathcal{U}(b) & \equiv \mathcal{U}(-b, b)
\end{align}
The convolution with a uniform distribution arises from the need to saturate a Gaussian distributed  $y_n$ between allowed values $|y_n| \leq b = 0.5$ for our application such that the resulting probability distribution of $y_n$ retains positivity. 





\subsection{Gaussian Process Regression (GPR)}

In GPR, dephasing noise correlations in the measurement record can be learned if one projects data on a distribution of Gaussian processes, $Pr(\state)$ with an appropriate encoding of their covariance relations via a kernel, $\Sigma_\state^{n_1, n_2}$. We define scalar noisy observations $y_{n}$ corrupted by Gaussian noise as above.  %In a linear measurement regime, let $\state_n$ be the true random phase belonging to the process $\state$ at time step $n$. 
%Our measurement record is corrupted by additive zero mean white Gaussian noise, $v_n$ with scalar covariance strength $R$, yielding scalar noisy observations $y_n$:
%\begin{align}
%y_n &= \state_n + v_n \\
%v_n & \sim \mathcal{N}(0, R) \quad \forall n
%\end{align}
Under linear operations, the distribution of measured outcomes, $y$, is also a Gaussian. The  mean and variance of $Pr(y)$  depends on the mean $\mu_\state$ and variance $\Sigma_\state$ of the prior $Pr(\state)$, and the mean $\mu_v \equiv 0$ and variance $R$ of the measurement noise, $v_n$: 
\begin{align}
\state & \sim Pr_\state(\mu_\state,\Sigma_\state ) \\
y & \sim Pr_y(\mu_\state,\Sigma_\state + R ) 
\end{align}
For covariance stationary $\state$, correlation relationships depend solely on the time lag, $\nu \equiv \Delta t|n_1 - n_2|$ between any two time points  $n_1, n_2 \in [-N_T, N_P]$.  An element of the covariance matrix, $\Sigma_\state^{n_1,n_2}$, corresponds to one value of lag, $\nu$, and the correlation for any given $\nu$  is specified by the covariance function, $R(\nu)$:
\begin{align}
\Sigma_\state^{n_1,n_2} & \equiv R(\nu) 
\end{align}
Any unknown parameters in the encoding of correlation relations via $R(\nu)$ are learned by solving the optimisation problem outlined in \cref{sec:main:Optimisation}. The optimised GPR model is then applied to datasets corresponding to new realisations of the dephasing process. Let indices $n \in N_T \equiv [-N_T, 0]$ denote training points, and let a length $N^{(\star)} $ vector contain arbitrary testing points $n^{(\star)} \in [-N_T, N_P]$. These testing points in machine learning language encompass both state estimation and prediction points in our notation. We now define the joint distribution $Pr(y,\state^{(\star)})$, where $\state^{(\star)}$ represents the true process evaluated by GPR at desired test points: 
\begin{align}
\begin{bmatrix} \state^{(\star)} \\y \end{bmatrix} & \sim \mathcal{N} (\begin{bmatrix} \mu_{\state^{(\star)}} \\ \mu_y
\end{bmatrix} , \begin{bmatrix}   K(N^{(\star)},N^{(\star)})&K(N_T,N^{(\star)}) \\ K(N^{(\star)},N_T) & K(N_T,N_T) + R \end{bmatrix} )
\end{align}
The additional `kernel' notation $\Sigma_\state  \equiv K(N_T, N_T)$ is ubitiquous in GPR. Time domain correlations specified by $R(\nu)$ populate each element of a matrix $K(\cdot, \cdot \cdot)$, where the dimensions of the matrix depend on the vector length of each argument. For $K(\cdot{},\cdot)$, the notation defines a square matrix where diagonals correspond to $\nu=0$ and off-diagonal elements correspond to separation of two arbitrary points in time i.e. $\nu \neq 0 $. 
 
Following \cite{rasmussen2005gaussian}, the moments of the conditional predictive distribution $Pr(\state^{(\star)}|y)$ can be derived from the joint distribution $Pr(y,\state^{(\star)})$ via standard Gaussian identities:
\begin{align}
\mu_{\state^{(\star)}|y} &= \mu_\state + K(N^{(\star)},N_T)(K(N_T,N_T) + R )^{-1} (y - \mu_y) \\
\Sigma_{\state^{(\star)}|y} &= K(N^{(\star)},N^{(\star)}) \nonumber \\
& - K(N^{(\star)},N_T)(K(N_T, N_T) + R)^{-1}K(N_T,N^{(\star)}) 
\end{align}
The above prediction procedure holds true for any choice kernel, $R(\nu)$. In any GPR implementation, the dataset, $y$, constrains the prior model yielding an aposteriori predictive distribution. The mean values of this predictive distribution, $\mu_{\state^{(\star)}|y}$, are the state predictions for the qubit under dephasing at test points in $N^{(\star)}$.

Our choice of a `periodic kernel' in this manuscript encodes a covariance function which is theoretically guaranteed to approximate any zero-mean covariance stationary process, $\state$, in the mean square limit, namely, by having the same structure as a covariance function for trigonometric polynomials with infinite harmonic terms \cite{solin2014explicit, karlin2012first}. The sine squared exponential kernel represents an infinite basis of oscillators and can be summarised as:
\begin{align}
R(\nu) &\equiv \sigma^2 \exp (- \frac{2\sin^2(\frac{\omega_0^{(B)}\nu}{2})}{l^2}) 
% R(v) &=  \sigma^2 \exp (- \frac{1}{l^2}) \sum_{n = 0}^{\infty} \frac{1}{n!} \frac{\cos^n(\omega_0^{(B)}\nu)}{l^{2n}} \\
\end{align} 
This kernel is summarised by just two key hyper-parameters: the frequency comb spacing for our infinite basis of oscillators, $\omega_0$, and a dimensionless length scale, $l$. We use physical sampling considerations to approximate their initial conditions prior to an optimisation procedure, namely, that the longest correlation length encoded in the data, $N \Delta t $, sets the frequency resolution of the comb, and the scale at which changes in $\state$ are resolved is of order $\Delta t$:
\begin{align}
\frac{\omega_0^{(B)}}{2\pi} & \sim  \frac{1}{\Delta t N} \\
l & \sim \Delta t
\end{align} 
Because the periodic kernel can be shown to be formally equivalent to the basis of oscillators employed in the LKFFB algorithm, the inclusion of GPR using this kernel permits a comparison of the underlying algorithmic structures for the task of predictive estimation.  A derivation is provided in Appendices using commentary in \cite{solin2014explicit}.

In our analyses we exclude popular kernel choices such as the Gaussian kernel (RBF)and  a scale mixture of Gaussian kernels (RQ) \cite{rasmussen2005gaussian, tobar2015learning}. These exclusions are based on kernel properties as follows. An arbitrary-scale mixture of zero mean Gaussian kernels will probe an arbitrary area around zero in the Fourier domain, as schematically depicted in \cref{fig:main:Predive_control_Fig_overview_17_two}(a). While such kernels capture the continuity assumption ubitiquous in machine learning, they are structurally inappropriate in probing a dephasing noise process of an arbitrary power spectral density (e.g. ohmic noise).  


\section{Algorithm Performance Characterisation \label{sec:main:Performance}}

In the results to follow, our metric for characterising performance of optimally tuned algorithms will be the normalised Bayes prediction risk:
\begin{align}
\normpr \equiv \frac{L_{BR}(n|I)}{\langle \state_n^2 \rangle_{\state, \mathcal{D}}} 
\end{align}
A desirable forward prediction horizon corresponds to maximal $n^* \in [0, N_P]$ for which normalised Bayes prediction risk at all time steps $n \leq n^*$ is less than unity. We compare the difference in maximal forward prediction horizons between algorithms in the context of realistic operating scenarios.  We begin here by introducing the numerical methods employed for generating data sets on which predictive estimation is performed


%\section{Noise Engineering and Simulated Measurements\label{sec:main:NoiseEngineering}}





%to enable future experimental verification of simulations reported in this manuscript. We generate $ N = N_T + N_P$ number of points in one sequence of true dephasing noise spaced $\Delta t $ apart in time. We define the discretised process, $\state$, as:
%\begin{align}
%\state_n &= \alpha \omega_0 \sum_{j=1}^{J} j F(j)\cos(\omega_j n \Delta t + \psi_j) \\
%F(j) & = j^{\frac{p}{2}-1} 
%\end{align}

%Using the notation of \cite{soare2014}, $\alpha$ is an arbitrary scaling factor, $\omega_0$ is the fundamental spacing between true adjacent discrete frequencies, such that $\omega_j = 2 \pi f_0 j =\omega_0 j, j = 1, 2, ...J$. For each frequency component, there exists a uniformly distributed random phase, $\psi_j \in [0, \pi]$. The free parameter $p$ allows one to specify an arbitrary shape of the true power spectral density of $\state$. In particular, the free parameters $\alpha, J, \omega_0, p$ are true dephasing noise parameters which any prediction algorithm cannot know beforehand. With uniformly distributed phase information, it is straightforward to show that $\state$ is mean square ergodic and covariance stationary \cite{gelb1974applied}. However, each $n^{th}$ member of the sequence $\state$ is Gaussian distributed only by the central limit theorum for large $J$ (in simulations, $J \approx 20$ satisfies Gaussianity, see Appendices). For results in this manuscript, we choose $p=0$ flat top spectrum - this choice of a power spectral density theoretically favors no particular choice of algorithm. For linear regimes, we choose $\alpha$ arbitrarily high relative to machine precision for recursive Kalman calculations, and in non-linear regimes, we use $\alpha$ to rescale $f \in [0, \pi]$ before taking projective measurements. 

%While $\{ \alpha, J, \omega_0, p \}$ represents true, unknown environmental dephasing, the choice of $\{N, \Delta t\} $ represents a sampling rate and Fourier resolution set by the experimental protocol. We choose regimes where Nyquist $r \gg 2$.

We simulate environmental dephasing through a Fourier-domain procedure described in \cite{soare2014} in order to simulate an $\state$ which is mean square ergodic and covariance stationary~\cite{gelb1974applied}.  For the results in this manuscript, we choose a flat top spectrum with a sharp high-frequency cutoff for simplicity as this choice of a power spectral density theoretically favors no particular choice of algorithm but shows strong non-Markovianity. 

In our simulations we also must mimic a measurement process which samples the underlying ``true'' dephasing process.  The algorithmic parameters $\{N, \Delta t\} $ represent a sampling rate and Fourier resolution set by the simulated measurement protocol; we choose regimes where Nyquist $r_{Nqy} \gg 2$. In generating noisy simulated measurement recrods, we corrupt a noiseless measurement by additive Gaussian white noise. Since $\state$ is Gaussian, the measurement noise level, $N.L.$ is defined as a ratio between the standard deviation of additive Gaussian measurement noise, $\sqrt{R}$ and the maximal spread of random variables in any realisation $\state$. We approximate the maximal spread of $\state$ as three sample standard deviations of one realisation of true $\state$, $N.L. = \sqrt{R}/3\sqrt{\hat{\Sigma}_\state^{n,n}}$. The use of a hat in this notation denotes sample statistics. This computational procedure enables a consistent application of measurement noise for $\state$ from arbitrary, non-Markovian power spectral densities. For the case where binary outcomes are required, we apply a biased coin flip using \cref{eqn:main:qkf:binomial}.

\subsection{Algorithmic Optimisation \label{sec:main:Optimisation}}

All algorithms in this manuscript employ machine learning principles to auto-tune unknown design parameters based on training datasets. The physical intuition associated with optimising our filters is that we are cycling through a large class of general models for environmental dephasing and seeking the model(s) which best fit the data subject to various constraints. This allows each filter to track stochastic qubit dynamics under arbitrary covariance-stationary, non-Markovian dephasing.  We elected to deploy an optimisation routine with minimal computational complexity to enable nimble deployment of KF and GPR algorithms in realistic laboratory settings, particularly since LSF optimisation is extremely rapid for our application \cite{mavadia2017}. 



Kalman filtering in our setting poses a significant challenge for general optimisers as the lack of theoretical bounds on the values of ($\sigma, R$) result in large, flat regions of the Bayes Risk function. Further, the recursive structure of the Kalman filter means that no analytical gradients are accessible for optimising a choice of cost function and a large computational burden is incurred for any optimisation procedure. We randomly distribute $(\sigma_{k}, R_{k})$ pairs for $k=1, \hdots K $ over several orders of magnitude in two dimensions in order to sample the optimisation space.

\iffalse %%%%%%%%%% THIS BELONGS IN THE APPENDIX, NOT THE MAIN TEXT AS ITS A NUMERICAL DETAIL
\begin{align}
\sigma_k, R_k &\equiv \iota_0 10^{\iota_1} \\
\iota_0 & \sim \mathcal{U}[0, 1]\\
\iota_1 & \sim \mathcal{U}[\{ -\iota_{max}, -\iota_{max} + 1,  \hdots,  \iota_{min}\}]
\end{align}
Scale magnitudes are set by $\iota_1$, a random integer chosen with uniform probability over $\{ -\iota_{max}, \hdots, \iota_{min} \}$ where we set $\iota_{min} = 3, \iota_{max} = 8$  such that $10^{-\iota_{max}}$ is sufficiently high to avoid machine floating point errors from recursive calculations over $> 10^3$ measurements. Uniformly distributed floating points for $\sigma_k, R_k $ in each order of magnitude is set by $\iota_0$. 
\fi

We then generate a sequence of loss values $L(\sigma_k, R_k)$ for each $k$ as
\begin{align}
L(\sigma_k, R_k) \equiv  \sum_{n=1}^{N'} L_{BR}(n | I= \{\sigma_k, R_k \}).
\end{align}
Here, $L_{BR}(n | I= \{\sigma_k, R_k \})$ is given by \cref{eqn:main:sec:ap_opt_LossBR} and it is summed over $0\leq N'\leq |N_{T}|$  ($0\leq N'\leq |N_{P}|$) backwards (forwards) time steps for state estimation (prediction). Values of $N'$ are chosen such that the sequence $\{L(\sigma_k, R_k) \}$ defines sensible shapes of the total loss function over parameter space and the numerical experiments in this manuscript. A choice of small $N'$ in state-estimation ensures that data near the prediction horizon are employed - a region where the Kalman filter is most likely to have converged.  Similarly, in state prediction, large $N'$ will flatten the true prediction loss function as long-term prediction errors dominate smaller loss values occurring during the short term prediction period.  While simple and by no means optimal, our approach is computationally efficient given the recursive nature of the Kalman filter.% and a quantitative review of Bayesian hyper-parameter optimisation procedures is beyond the scope of this manuscript. One may incorporate a different prior over $I= \{\sigma_k, R_k \}$ and/or construct optimisation problem over different choices of cost function (e.g. maximum likelihood).

An ideal parameter pair ($\sigma^*, R^*$) minimises Bayes risk over $K$ trials for both state estimation and prediction.  We define acceptable low loss regions for state estimation and prediction as being the set which returns loss less than $10\%$ of the media risk over $K$ trials.  

In the event that low risk regions do not exist for both state estimation and prediction for a given parameter pair, we deem the optimisation to have failed as backwards state estimation performance is uncorrelated with forward prediction (for illustration see lower panels of \cref{fig:main:fig_data_specrecon}).

In GPR the set of parameters $I = \{\sigma, R, \omega_0^{(B)}, l \}$ requires optimisation.  However, in contrast to the KF, no recursion exists and analytic gradients are accessible to simplify the overall optimisation problem; instead of minimising Bayes state-estimation risk, we follow a popular practice of maximising the Bayesian likelihood. Initial conditions and optimisation constraints are derived from physical arguments as described in \cref{sec:main:OverviewofPredictive Methodologies}.% to provide initial conditions and/or to constrain the optimisation of $\{ \omega_0^{(B)}, l\}$. 

\subsection{Performance of the KF using linear measurement}
\begin{figure}
    \includegraphics[scale=1.0]{fig_data_state_pred}
    \caption{\label{fig:main:fig_data_all} TBC}
    \end{figure}  
    % \caption{\label{fig:main:fig_data_all} We plot state predictions against time steps $n > -50$ obtained from optimised AKF, LKFFB and LSF algorithms for $K=75$ trials. We plot true $\state$ [black] and measurement data [grey dots], where measurements for $n \in [-N_T, -50]$ are omitted [(left)]. A single run contributes to Bayes prediction risk over an ensemble of $M=50$ runs normalised against predicting the mean, $\mu_\state$, of dephasing noise [right]. A normalised risk $<1$ for $n > 0$ defines a desirable forward prediction horizon. A single run phase sequence $\state$ is drawn from a flat top spectrum with $J$ true Fourier components spaced $\omega_0$ apart and uniformly randomised phases $\in [0, 2\pi]$. A trained LKFFB is implemented with comb spacing $\omega_0^{(B)} / 2\pi = 0.5$ Hz and $J^{(B)} =100$ oscillators; while trained AKF / LSF models correspond to high $q = 100$. Relative to LKFFB,  (a) and (b) correspond to perfect projection $\omega_0 / \omega_0^{(B)}  \in \mathcal{Z} $ for $J= 40, \omega_0 / 2\pi = 0.5$ Hz. In (c) and (d), we simulate realistic noise with $\omega_0 / \omega_0^{(B)}  \notin \mathcal{Z}$, $J = 45000$, $\omega_0 / 2\pi = \frac{8}{9} \times 10^{-3}$ Hz such that $>500$ number of true components fall between adjacent LKFFB oscillators. For (a)-(d), $N_T = 2000, N_P = 100$ steps, $\Delta t = 0.001s$ such that we fulfill $r_{Nqy} \gg 2$, $N_T / \Delta t < \omega_0/2\pi$. Measurement noise level $ N.L.= 10\%$.}


%\subsubsection{General predictive performance}

As an illustration of general performance of the various KF algorithms discussed above, Fig.~\ref{fig:main:fig_data_all} depicts the performance of predictive estimation using the AKF and LKFFB algorithms and a linear measurement record.  Here the solid black line represents the underlying true $\state$ and round markers indicate noisy simulated linear measurement data.  These data are used in all predictive-estimation KF routines and we include a comparison to the (non-iterative) LSF employed in~\cite{mavadia2017}.  In panels (a) and (c) we show single time-domain realisations of $\state$  and associated predictions while, where predictions match future evolution of $\state$ to varying degrees.  In panels (b) and (d) we plot the ensemble-averaged $\normpr$ prediction risk as a function of forward timesteps.  Here successful prediction occurs so long as $\normpr\lesssim \mu_{f_{n}}$, the mean value of $\state$ indicated by the solid horizontal line. Here, all protocols allow successful forward prediction with similar overall performance.

We treat two different numerical regimes in order to reveal the importance of the underlying structure of the algorithm defining the dynamical model in the Kalman framework.  In panels (a) and (b), we depict a case in which perfect projection of the true $\state$ in the LKFFB basis is \textit{theoretically} achievable.  Here we find that LKFFB learns all information about the dephasing noise and qubit state dynamics are nearly perfectly predictable.  By comparison AKF and LSF cannot extract all information from measurements of $\state$ and demonstrate inferior relative performance.The AKF and LSF share autoregressive coefficients and therefore both algorithms demonstrate comparable $\normpr$ prediction risk trajectories. 

The numerical condition of perfect projection of $\state$ dynamics onto the LKFFB basis is relaxed in panels (c) and (d).  We engineer $\state$ such any true spectral component in $\state$ can never be perfectly projected on an LKFFB basis frequency. Further, we enforce a condition commensurate with limited computational resolution for any practical application, namely $J \gg J^{(B)}$, the number of frequencies used in defining the noise greatly exceeds the number appearing in the LKFFB basis.  These constraints lea to a significant degradation of performance for the LKFFB while general performance of the AKF and LSF are unaffected. 

In general our objective is to maximise the forward prediction horizon in any algorithmic setting.  In Fig.~\ref{fig:main:fig_data_all} we explore the key determining factors setting the value of the prediction horizon under the three main Kalman filtering algorithms treated here.  We plot the ensemble-averaged $\normpr$ as a function of forward prediction time when adjusting the ratio of the cutoff frequency in the noise $\omega_{c}=J\omega_{0}$ to the sample rate in the measurement routine, defined as $\omega_{S}=2\pi/\Delta t$.  We see that the prediction horizon (indicated approximately by dashed vertical lines) increases as the measurement becomes sufficiently fast to sample the highest frequency dynamics of $\state$ under all cases.  We confirm that absolute prediction horizons for any algorithm are arbitrary and adjustable by the sample rate, allowing us torestrict our analysis to comparative statements between algorithms for future results.  While differences between protocols appear reasonably small we note that in most cases examined the AKF demonstrates superior performance to the LKFFB subject to the realistic constraint that the true dynamics of $\state$ cannot be perfectly projected onto the basis used in LKFFB (corresponding to substantial a priori knowledge of the dynamics of $\state$).
\\
\\
% \begin{figure}
%     \includegraphics[scale=1.0]{fig_data_all}
%     \caption{\label{fig:main:fig_data_all} From (a)-(c), we plot $\normpr$ against forward time $n \in [0, N_P]$ for LSF, AKF and LKFFB. In each panel, we vary true $\state$ cutoff relative to an apriori noise bandwidth assumption $f_{(B)}$ such that $\omega_0 / 2\pi = 0.497$ Hz, $J = 20, 40, 60, 80, 200$. In this simple case, all Fourier components can be theoretically seen in the data. We depict the maximal forward prediction horizon for each case using vertical lines at approximately $ n_{max} \mid  \normpr \lesssim 0.8 < 1$, where a threshold less than unity is chosen to reduce artifacts arising from Bayes risk oscillations around mean behaviour. For LKFFB, $\omega_0^{(B)} / 2\pi = 0.5$ Hz for $j \in J^{(B)} = 100$ oscillators. For LSF and AKF, $q = 100$. In all cases,  $N_T = 2000, N_P = 50$ steps, $\Delta t = 0.001s, r_{Nqy}=20$, with optimisation performed for $M=50$ runs, $K=75$ trials and measurement noise level $N.L. = 1\%$. } 
% \end{figure} 



%\subsubsection{Spectral estimation of $\state$}



\begin{figure}[b]
    \includegraphics[scale=1.]{fig_data_akfvlsf}
    \caption{\label{fig:main:fig_data_akfvlsf} (a) Ratio of $\normpr$ prediction risk from AKF to LSF against time steps $n>0$.  AKF and LSF share identical $\{ \phi_q \}$ and  a value below $<1$ indicates AKF outperforms LSF. In (i)-(iv), applied measurement noise level is increased from $0.1 - 25 \%$. (b) Normalised Bayes Risk vs time steps $n>0$ for AKF and LKFFB corresponding to cases (i) -(iv) and confirm a desirable forward prediction horizon underpins ratios in (a). True $\state$ is drawn from a flat top spectrum with $\omega_0 / 2\pi = \frac{8}{9} \times 10^{-3}$ Hz, $J = 45000$, $N_T = 2000, N_P = 100$ steps, $\Delta t = 0.001s, r_{Nqy}=20$ such that \cref{fig:main:figure_lkffb_path}(c) corresponds to case (ii) in this figure. Optimisation is performed for $M=50$ runs, $K=75$ trials.}
\end{figure}

    \begin{figure*} [htp]
    \includegraphics[scale=1.0]{figure_lkffb_path}
    \caption{\label{fig:main:figure_lkffb_path} 
    Comparison of KF performance under various imperfect learning scenarios.  The relationship between LKFFB basis and true noise spectrum characteristics shown schematically above each column.   (a)-(d) by varying  $\omega_0 / 2\pi = 0.5, 0.499, \frac{8}{9} \times 10^{-3}, \frac{8}{9} \times 10^{-3}$ Hz and $J = 80, 80, 45000, 80000$ respectively. For (a)-(d), we depict normalised Bayes prediction risk for LKFFB, AKF, and LSF against time steps $n>0$. For LKFFB, these regimes correspond to perfect learning in (a); imperfect projection on basis in (b); finite computational Fourier resolution in (c); and a relaxed bandwidth assumption ($f_{(B)} < \omega_0 / 2\pi$) in (d). In the panels (e)-(l), we depict optimisation of Kalman noise parameters ($\sigma^2, R$) for LKFFB [top row] and AKF [bottom row] for the four regimes in (a)-(d). Low loss regions represent risk values $< 10\%$ of $L_0$, the median risk incurred during Kalman hyperparameter optimisation for $K=75$ trials of of randomised ($\sigma^2, R$) pairs. Optimal ($\sigma^*, R^*$) minimise state estimation risk. For each trial, a risk point is an expectation over $M=50$ runs of true $\state$ and noisy datasets during state estimation ($n \in  [-N_{SE}, 0]$) or prediction ($n \in  [0, N_{PR}]$). We choose $ N_{PR}=N_{SE}=50$ such that the shape of total loss over time steps form sensible optimsation problems and a scan of $N_{PR}, N_{SE}$ values do not appear to simplify our Kalman optimisation problem. We plot optimisation results for LKFFB in (e)-(h) and AKF in (i)-(l). A KF filter is `tuned' if optimal ($\sigma^*, R^*$) lies in the overlap of low loss regions for state estimation and prediction. This condition is violated in (h). KF algorithms are set up with $q = 100$ for AKF; $J^{(B)} = 100, \omega_0^{(B)} / 2\pi = 0.5$ Hz for LKFFB, with $N_T = 2000, N_P = 100$ steps, $\Delta t = 0.001s, r_{Nqy}=20$ and applied measurement noise level $ N.L. = 1\%$.}  
    \end{figure*} 


A key implied benefit of the use of Kalman filtering vs general least-squares filtering is the addition of robustness against measurement noise.  In order to probe this we perform direct comparisons of filter performance under varying measurement noise strength for both the AKF and LSF.  This approach highlights the iterative algorithmic structure of the KF in filtering measurement noise as the AKF algorithm recasts an AR($q$) process from LSF directly into Kalman form.  In \cref{fig:main:fig_data_akfvlsf} (a), we plot $\normpr$ prediction risk for AKF and LSF as a ratio such that a value greater than unity implies LSF outperforms AKF.
%\begin{align}
%AKF / LSF \equiv \frac{\normpr ^{AKF}}{\normpr^{LSF}}, \quad n \in [0, N_P]
%\end{align}
In cases (i)-(iv), we increase the applied noise level to our datasets $\{ y_n \}$ representing simulated measurements on $\state$. For applied measurement noise level $N.L. > 1\%$ in (ii)-(iv), we find that $AKF/LSF <1 $ and AKF outperforms LSF for the conditions studied here, with a general trend towards increasing benefits as noise increases until the noise becomes so large (iv) that the benefits fluctuate as a function of $n$. Calculations of the ensemble-averaged $\normpr$ in Fig.~\ref{fig:main:fig_data_akfvlsf} (b) demonstrate that all ratios reported in (a) correspond to a useful forward prediction horizon. 





%\subsubsection{Model robustness}
In machine learning or optimal control settings, the robustness of the learning procedure to small changes in the underlying system is an essential characteristic of the algorithm.  In our case, we have already seen that the quality of projection of the true dynamics of $\state$ onto the LKFFB basis can have a significant impact on the quality of learning and predictive estimation.  Here we explore this initial finding in more detail.  

 In Fig.~\ref{fig:main:figure_lkffb_path}, we simulate various learning conditions including (a) perfect learning in LKFFB; (b) imperfect projection relative to the LKFFB basis; (c) imperfect projection combined with finite algorithm resolution; and (d), imperfect learning and undersampling relative to true noise bandwidth. The ordering of figure presentation highlights the degree of impact of the introduced pathologies on LKFFB.  By contrast we find reasonable model robustness in AKF/LSF at the expense of performance in the somewhat unrealistic perfect learning case.  

We expose the underlying optimisation results for choosing an optimal $(\sigma^*, R^*)$ for LKFFB in Fig.~\ref{fig:main:figure_lkffb_path} (e)-(h) and for AKF in Fig.~\ref{fig:main:figure_lkffb_path} (i)-(l). Individual sample points are highlighted as sold markers while low-loss pairs in this 2D space are highlighted for giving low state-estimation (purple) or prediction (crimson) risk via shaded circles.  As the model pathologies indicated above increase, these data demonstrate a divergence between regions of the optimisation space which permit low-loss state estimation and forward prediction for LKFFB.  In contrast, overlap of low loss Bayes Risk regions do not change for AKF across Fig.~\ref{fig:main:figure_lkffb_path} (i)-(l).



Kalman filtering algorithms employed here combine iterative state estimation with the establishment of a dynamical model in the Fourier domain.  Therefore one way to explore algorithmic performance is to look directly at the efficacy of spectral estimation relative to the true (here numerically engineered) hidden dynamics of $\state$.  For both the LKFFB and AKF we plot the extracted power spectral density, $S(\omega)$ as a function of angular frequency $\omega$ for different measurement sampling conditions in Fig.~\ref{fig:main:fig_data_specrecon} against the true spectrum used to define $\state$.  These measurement conditions match those introduced in Fig.~\ref{fig:main:fig_data_all}.

In the case of LKFFB, we plot the learned instantaneous amplitudes from a single run (blue markers) and for AKF we extract optimised algorithm parameters as described above (red markers). Under the assertion that the LSF implements an AR($q$) process, the set of trained parameters, $\{  \{\phi_{q' \leq q}\}, \sigma^2\}$ from AKF allows us to derive experimentally measurable quantities, including the power spectral density of the dephasing process \cite{brockwell1996introduction}:
%\begin{align}
$S(\omega) = \sigma^2/ 2 \pi |\Phi(e^{-i\omega}, q)|^2$ %\label{eqn:main:ap_ssp_ar_spectden}  
%\end{align}
Here, we use the same summarised notation, $\Phi(\mathcal{L}, q)$, but  $\mathcal{L}$ is no longer the time domain lag operator and has been redefined as $e^{-i\omega}$ to enable a Fourier domain calculation using $q$ autoregressive coefficients. 

\begin{figure}[tp]
    \includegraphics[scale=1.0]{fig_data_specrecon}
    \caption{\label{fig:main:fig_data_specrecon} Comparison of the true power spectrum for $\state$ with derived spectral estimates from LKFFB and AKF. From (a)-(d), we vary true $\state$ cutoff relative to an apriori noise bandwidth assumption $f_{(B)}$ such that $\omega_0 / 2\pi = 0.5$ Hz, $J = 20, 40, 80, 200$. For LKFFB, we use learned amplitude information from a single run ($\propto ||x^j_n||^2 $) with $\omega_0^{(B)} / 2\pi = 0.497$ Hz for $j \in J^{(B)} = 100$ oscillators. For AKF, we plot $S(\omega)$ using optimally trained $\{\phi_{q' \leq q}\}$ and $\sigma^2$, with order $q = 100$. The zeroth Fourier component and its estimates are omitted to allow for log scaling; and $N_T = 2000, N_P = 50$ steps, $\Delta t = 0.001s, r_{Nqy}=20$, with optimisation performed for $M=50$ runs, $K=75$ trials and measurement noise level $N.L. = 1\%$.} 
\end{figure} 

The critical feature in these data sets is the existence of a flat-top spectrum possessing a sharp high frequency cutoff.  Both classes of Kalman filtering algorithm successfully identify this structure and locate the high-frequency cutoff.  In general, however, the LKFFB provides superior spectral estimation relative to the AKF, better estimating the signal strength in the Fourier domain even in the presence of imperfect projection of $\state$ onto the basis used in LKFFB.  The only case in which the LKFFB fails is in Fig.~\ref{fig:main:fig_data_specrecon}(d), where the underlying assumption of oversampling is violated.  

The observed behavior is somewhat surprising given the generally superior performance of the AKF in predictive estimation, but does highlight the practical difference between Fourier-domain spectral estimation and time-domain prediction.  The performance of the AKF in this procedure is determined by the accuracy of the scaling factor given by optimally tuned parameter $\sigma$, pointing to the importance of optimisation for algorithmic performance. In contrast, instantaneous amplitudes are tracked in one run of LKFFB and are less susceptible to optimisation over model parameters.


\newpage
\subsection{Performance of the quantised Kalman filter}
The discrete nature of data sets in quantum systems subject to projective measurement poses a potential challenge for Kalman filters in the event that measurement pre-processing as in Fig.~\ref{fig:main:Predive_control_Fig_overview_17_one}(b) is not performed.  We test filter performance for predictive estimation when only binary measurement outcomes are available via the QKF.  To re-iterate, QKF estimates and tracks hidden information, $\state$, using the Kalman true state $x$.  In our construction the associated probability for a projective qubit measurement outcome, $\propto z$ is not inferred or measured directly but given deterministically by Born's rule encoded in the non-linear measurement model, $z = h(x)$. The measurement action is completed by performing a biased coin flip, where $z$ determines the bias of the coin.  

In Fig.~\ref{fig:main:fig_data_qkf2}, the ensemble-averaged risk, $\text{N.} \langle (z_n - \hat{z}_n)^2 \rangle_{f, \mathcal{D}} $, is calculated with respect to $z$ as the relevant quantity parameterising qubit-state evolution, instead of the stochastic underlying $\state$. We investigate if $\text{N.} \langle (z_n - \hat{z}_n)^2 \rangle_{f, \mathcal{D}} < 1, n\in [0, N_P] $ can be achieved for numerical experiments considered previously in the linear regime. In particular, we generate true $\state$ defined in numerical experiments in \cref{fig:main:fig_data_all,fig:main:fig_data_specrecon} for $q=100$ and varying sample rates.

We isolate the role of the measurement action by first inputting into the QKF a true dynamical model rather than a dynamical model learned as in the standard AKF.  To specify true dynamics, we approximate $\state$ by $f'$, where $f'$ is generated from a sequence of $\{ \phi_{q'\leq q}\}$ obtained from LSF acting on $\state$ in the linear regime considered previously.  Hence, the QKF in (a) incorporates true dynamics and noise parameters $\{\{\phi_{q' \leq q} \}, \sigma, R\}$ but simply acts on single shot qubit measurements.  These simulations reveal that subject to generic measurement oversampling conditions introduced above the QKF is able to successfully enable predictive estimation.  As in the linear case, the absolute forward prediction horizon is arbitrary relative to $\omega_0 J / \omega^{(B)}$ and implicitly, an optimisation over the choice of $q$ in our application. 

\begin{figure}[h!]
    \includegraphics[scale=1.]{fig_data_qkf}
    \caption{\label{fig:main:fig_data_qkf2} Bayes prediction risk for QKF against time steps $n>0$. In (a)-(b), we vary true $\state$ cutoff relative to an apriori noise bandwidth assumption such that $J f_0 / f_{(B)} = 0.2, 0.4, 0.6, 0.8$ for an initially generated true $\state$ in \cref{fig:main:fig_data_specrecon} with $\omega_0/ 2\pi = 0.497 $ Hz, $J = 20, 40, 60, 80$. Measurement noise is incurred on $\state$ at $N.L. = 1 \%$ for the linear measurement record and on $z$ at $N.L. = 1\%$ level corresponding to the non-linear measurement record. In (a), we obtain $\{\phi_{q' \leq q}\}, q=100$ coefficients from AKF/LSF acting on a linear measurement record generated from true $\state$. We re-generate a new truth, $f'$, from an autoregressive process by setting $\{\phi_{q'\leq q}\}, q=100$ as true coefficients and by defining a known, true $\sigma$. We generate quantised measurements from $f'$ and data is corrupted by measurement noise of a true, known strength $R$. In (b), we use $\{\phi_{q' \leq q} \}, q=100$ coefficients from (a) but we generate quantised measurements from the original, true $\state$. We auto-tune QKF noise design parameters in a focused region ($\sigma_{AKF}^* \leq \sigma_{QKF}$, $R_{AKF}^* \leq R_{QKF}$) with with $M=50$ runs, $K=75$ trials. For (a)-(b), forward prediction horizons are shown with $N_T = 2000, N_P = 50$ steps, $\Delta t = 0.001s, r_{Nqy}\gg 2$.}
\end{figure}


%By using $f'$, QKF incorporates a high $q$ true autoregressive dynamical model $\{ \phi_{q'\leq q}\}$. We generate single shot qubit measurements based on $f'$ and we input true noise parameters $(\sigma, R)$. \cref{fig:main:fig_data_qkf2} (a) depicts that a desirable forward prediction horizon $\text{N.} \langle (z_n - \hat{z}_n)^2 \rangle_{f, \mathcal{D}} < 1, n\in [0, N_P] $ is achieved for sufficiently oversampled regime, and the forward prediction horizon shrinks in $n$ when oversampling is reduced. \\

Our simulations reveal that the QKF is considerably more sensitive to measurement noise and the degree of oversampling than the linear model as shown in Fig.~\ref{fig:main:fig_data_qkf2} (b). Here the QKF incorporates a learned dynamical model from AKF in the linear regime and we tune $(\sigma, R)$ for use in the QKF.  In particular, we explore $\sigma \geq \sigma_{AKF}^*$ to incorporate model errors as $\{\phi_{q' \leq q}\}$ were learned in the linear regime.  We also incorporate increased measurement noise via $R \geq R_{AKF}^*$ as QKF receives raw data that has not been pre-processed or low-pass filtered. The underlying optimisation problems are well behaved for all cases in \cref{fig:main:fig_data_qkf2}(b) [not shown].  As oversampling is reduced, the QKF forward prediction horizon disappears rapidly i.e $\text{N.} \langle (z_n - \hat{z}_n)^2 \rangle_{f, \mathcal{D}} > 1 $ prediction risk for all $n>0$.  




\subsection{GPR} 
Our investigations reveal that GPR using the periodic kernel is not able to perform simultaneous state estimation and forward prediction.  In order to demonstrate this and the underlying failure mechanism we dramatically simplify the model used for $\state$ and replace it with a single-frequency sine curve.  Figure~\ref{fig:main:fig_data_gpr} demonstrates the prediction routine conducted on this version of $\state$ where prediction is always conducted from time-step zero.   For this simple example, the periodic kernel learns Fourier information in the measurement record enabling interpolation using test-points $n^{(\star)} \in [-N_T, 0]$ for all cases (a)-(d) in \cref{fig:main:fig_data_gpr}. Time domain predictions $n^{(\star)} >0$  in (a) appear sensible when perfect learning is possible given the theoretical structure of the simulation. By contrast, when learning is imperfect in (b)-(d), GPR predictions for the region  $n^{(\star)} \in [0, N_P]$ show a pronounced discontinuity.

An examination of different cases for imperfect learning reveal that this discontinuity exhibits deterministic behavior linked to the underlying structure of the algorithm.  FORMALLY DEFINE AND EXPLAIN KAPPA.  The time at which the discontinuity occurs is set by the value of $\kappa$, as indicated by the vertical dashed lines in all panels of Fig.~\ref{fig:main:fig_data_gpr}.  However another feature appears which we identify as being linked to oversampling of the underlying process determining $\state$.  In such cases the algorithm simply predicts zero out to $n=\kappa$ before discontinuously predicting future evolution which does not appear similar to the true value of $\state$.

In Fig.~\ref{fig:main:fig_data_gpr} we also plot the value of $\state$ as given from $n=-N_{T}$, the start of the data set, on top of the prediction from $n=\kappa$.  Here we see that the prediction provided by GPR matches the earliest stages of the underlying data set well.  Through various numeric experiments we find that the action of GPR in such circumstances appears to be to simply repeat the learned values of $\state$ from $n=-N_{T}$ beginning at $n=\kappa$.  Accordingly these predictions rarely describe the underlying forward dynamics of $\state$ well.




 
\begin{figure}
    \includegraphics[scale=1.]{fig_data_gpr}. 
    \caption{\label{fig:main:fig_data_gpr} In (a)-(d), prediction points $\mu_{\state^*|y}$ [purple] are plotted against time steps, $n$. We plot the true phase sequence,  $\state$, [black] and  $\state$ at the beginning of the run [red dotted]. Predictions are generated in a single run by a trained GPR model with a periodic kernel corresponding to a Fourier domain basis comb spacing, $\omega_0^{(B)}$. Data collection of $N_T$ measurements [not shown] ceases at $n=0$. For simplicity, the true $\state$ is a deterministic sine with frequency, $\omega_0$. (a) Perfection projection is possible $\omega_0 / \omega_0^{(B)} \in \mathcal{Z}$ natural numbers, $\omega_0 = 3$ Hz. Kernel resolution is exactly the longest time domain correlation in dataset, $2 \pi / \omega_0^{(B)} \equiv \Delta t N_T \implies \kappa = 0$.   (b) Imperfect projection, with $\omega_0 / \omega_0^{(B)} \notin \mathcal{Z}$, $\omega_0 / 2 \pi = 3 \frac{1}{3}$ Hz, $\kappa=0$. (c) We increase kernel resolution to be arbitrarily high, $\kappa \gg 0 $, such that $\omega_0 / \omega_0^{(B)} \gg 0 \notin \mathcal{Z}$ for original $ \omega_0 / 2 \pi = 3$ Hz. (d) We test (b) and (c) for $\kappa \gg0$, $ \omega_0 / \omega_0^{(B)} \notin \mathcal{Z}$, $\omega_0 / 2 \pi = 3 \frac{1}{3}$ Hz. For all (a)-(d), $N_T = 2000, N_P = 150$ steps, $\Delta t = 0.001s$ and applied measurement noise level $1\%$.} 
\end{figure}

%When learning is imperfect in (b)-(d), GPR predictions for the region  $n^{(\star)} \in [0, N_P]$ show a pronounced discontinuity at a deterministic quantity, $\kappa$.  


\section{Discussion} \label{sec:main:discussion}
The numeric simulations we have performed probe a wide variety of operating conditions in order to probe the algorithmic pathologies of leading techniques drawn from the engineering and computer science communities.  Our central finding is that overall the autoregressive Kalman filter provides an effective path to perform both state estimation and forward prediction for non-Markovian qubit dynamics. The AKF, importantly, provides model robustness against details of the underlying dynamics as well as filtering of noise that allows it to outperform least-squares filters.  There are two theoretical reasons for why this is the case: measurement noise filtering is enabled in the Kalman framework through the optimisation procedure for $R$ and has a regularising (smoothening) effect. Secondly, an imperfectly learned dynamical model $\Phi$ is optimised through the tuning of $\sigma$. The joint optimisation procedure over $(\sigma, R)$ ensures that the relative strength of noise parameters is also optimised.  The 

AKF has also been demonstrated to work well with either linearised or discretised projective measurement models via what we refer to as the QKF.  In QKF, we employ single-shot, discretised qubit data while enabling model-robust qubit state tracking and increased measurement noise filtering via the underlying AKF algorithm.  However we find that the QKF is vulnerable to the build of errors for arbitrary applications and we provide three explanatory remarks from a theoretical perspective. Firstly, the Kalman gains are recursively calculated using a set of \text{linear} equations of motion which incorporate the Jacobian $H_n$ of $h(x_n)$ at each $n$. All non-linear Kalman filters perform well if errors during filtering remain small such that the linearisation assumption holds at all time steps. Secondly, measurements are quantised and hence residuals must be one of $\{-1, 0, 1 \}$ rather than continuously represented floating point numbers.  In our case, the Kalman update to $x_n$ at $n$, mediated by the Kalman gain cannot benefit from a gradual reduction in residuals.  A third effect incorporates consequences of both quantised residuals and a non-linear measurement action. In linear Kalman filtering, Kalman gains can be pre-calculated in advance of the acquisition of any measurement data. Namely, the recursion of Kalman state-variances $P$, can be decoupled from the recursion of Kalman state-means, $x$ \cite{grewal2001theory}.  In our application, quantised residuals affect the Kalman update of $x$, and further, they affect the recursion for the Kalman gain via the state dependent Jacobian, $H_n$. These three effects cause the QKF to be extremely sensitive to a rapid build of errors during the filtering process such that meaningful predictive estimation becomes impossible.

In this context, we demonstrate numerically that the QKF achieves a desirable forward prediction horizon when build of errors during filtering are minimised, for example, by specifying Kalman state dynamics and noise strengths perfectly, and/or by severely oversampling relative to the true dynamics of $\state$.   At present, we simply interpret our results on the QKF as demonstration that one may in principle track stochastic qubit dynamics using single shot measurements under a Kalman framework.

 It is possible that QKF forward prediction horizons in realistic learning environments can be improved by solving the full $q+2$ optimisation problem for $\{\{ \phi_{q' \leq q}\}, \sigma, R\}$, rather than employing the approach taken in this manuscript. However, this poses its own challenges given the observations we make about the optimisation landscape even for the 2D optimisation problem faced in the AKF.  More sophisticated, data driven model selection schemes are described for both KF and kernel learning machines (such as GPR) in literature (e.g. \cite{arlot2009data, vu2015understanding}). Beyond standard local gradient and simplex optimisers, we consider coordinate ascent \cite{abbeel2005} and particle swarm optimisation techniques \cite{robertson2017particle} as promising, nascent candidates and their application remains an open research question. 

Our general results on the use of autoregressive models for building Kalman dynamical models stand in contrast to Fourier-domain approaches in LKFFB and GPR using a periodic kernel;  both showed significant performance degradation in cases when learning of state dynamics was imperfect.  In investigating the loss of performance for LKFFB, we find that the efficacy of this approach depends on a careful choice of a \textit{probe} (i.e. a fixed computational basis) for the dynamics of $\state$ capturing the effect of dephasing noise on the qubit.  In the imperfect learning regime of Fig.~\ref{fig:main:fig_data_all} and identically, Fig.~\ref{fig:main:fig_data_specrecon}, LKFFB reconstructs Fourier domain information to a high fidelity across a range of sampling regimes but is outperformed by AKF in the time domain (Fig.~\ref{fig:main:fig_data_all}). Since LKFFB tracks instantaneous amplitude and phase information explicitly for each basis frequency, the loss of LKFFB time-domain predictive performance must accrue from difficulty in tracking instantaneous phase, rather than amplitude, information. 

While difficulty of instantaneous phase estimation is likely to disadvantage the time-domain predictive performance of LKFFB, our results show that a Fourier-domain approach yields high fidelity reconstructions of power spectral density describing $\state$. In contrast to our time domain findings, these reconstructions are robust against imperfect projection on the LKFFB oscillator basis even as oversampling is reduced. This suggests that an application of LKFFB outside of predictive estimation could be tested against standard spectral estimation techniques in future work.

The failure of GPR for the task of time-domain predictive estimation has proved more striking, and matches observations from the robotic control community that GPR is ineffective in many control settings.  Again, we construct the protocol underlying GPR using an infinite basis of Fourier frequencies summarised by a \textit{periodic} kernel.  Our investigations reveal that predictions with a periodic kernel are useful for interpolation but have limited meaning for forward predictions for time steps $n >0$.  We find that a fundamental period is set by the frequency spacing in the kernel and we expect that learned Fourier information will repeat in the time domain deterministically at the fundamental period, namely, $\kappa$ in all cases depicted in \cref{fig:main:fig_data_gpr}. 

When learning is perfect, a repeated pattern can be interpreted as qubit state predictions and no discontinuities appear in forward predictions. When learning is imperfect, however, GPR with a periodic kernel is able to learn Fourier amplitudes to provide good retrodictive state estimates for $n<0$, but fails to permit forward prediction for $n>0$.  We believe this arises due to the lack of a formal procedure within GPR for actively  tracking and correcting phase information for each individual basis frequency at $n= \kappa$.  Since phase information can be recast as amplitude information for any fixed-frequency oscillator, one would naively expect that forward predictions can be improved by reducing the frequency spacing for an infinite basis of oscillators in the periodic kernel.  However, our findings invalidate this assertion; an increase in kernel resolution leads to probing of lower frequency data dynamics.  When the periodic kernel begins sampling frequencies corresponding timescales longer than the entire measurement record this results in an unphysical interpretation from the algorithms.  As such, the GPR algorithm predicts zero for $n \in [0, \kappa], \kappa > 0$, before reviving at $\kappa$.  In fact, if prediction test points were not specified beyond $\kappa$, then a flat region in prediction could easily be misinterpreted as predicting the mean value of zero-mean noise, rather than clearly appearing as a numerical artefact. 

It is possible that the choice of more complex kernels could resolve this algorithmic failure, but they bring additional complications which thus far remain unresolved in relation to the current application.  Matern kernels of order $q + 1/2$ correspond to an autoregressive processes of order $q$, which are naturally considered within the AKF in this manuscript. These, however, require a considerably more complex optimisation routine in order to find the relevant hyperparameters entering the algorithm.  We did not pursue this approach given the successes of the AKF and the observation of the difficulty of algorithmic optimisation explored in Sec.~\ref{sec:main:Optimisation}.  Another class of GPR methods, namely, spectral mixture kernels and sparse spectrum approximation using GPR have been explored in \cite{wilson2013, quia2010}. However, these techniques also require efficient optimisation procedures to learn many unknown kernel parameters, whereas the sine-squared exponential in the periodic kernel is parameterised only by two hyper-parameters.  Some literature suggests the use of a kernel which is the product of the periodic kernel with others representing white noise \cite{klenske2016gaussian}; a detailed investigation of the application of spectral mixture and kernel product methods for forward prediction beyond pattern recognition and with limited computational resources, remains an area of future investigation.



\section{Conclusion \label{sec:main:Conclusion}}

In this manuscript we provided a detailed survey of machine learning and filtering techniques applied to the problem of tracking the state of a qubit undergoing non-Markovian dephasing via a record of projective measurements.  We specifically considered the task of performing predictive estimation: learning dynamics of the system from the measurement record and then predicting evolution forward in time. To accommodate stochastic dynamics under arbitrary dephasing, and without an a priori dynamical model, we chose two Bayesian learning protocols - Gaussian Process Regression (GPR) and Kalman Filtering (KF).  All Kalman algorithms predicted the qubit state forward in time better than predicting mean qubit behaviour, indicating successful prediction, though an autoregressive approach to building the Kalman dynamical model demonstrated enhanced robustness relative to Fourier-domain approaches.  Forward prediction horizons could be arbitrarily increased for all Kalman algorithms by oversampling the underlying dephasing noise.  Our investigations included studies of both linear and non-linear measurement routines and validate the utility of the Kalman filtering framework for both.  In contrast, under GPR, we found numerical evidence that this approach enables retrodiction but not forward predictions beyond the measurement record.  

There are exciting opportunities for machine learning algorithms to increase our understanding of dynamically evolving quantum systems in real time using projective measurements. Quantum systems coupled to classical spatially or temporally varying fields provide opportunities for classical algorithms to analyse correlation information and enable predictive control of qubits for applications in quantum information, sensing, and the like. Moving beyond a single qubit, we anticipate that measurement records will grow in complexity allowing us to exploit the natural scalability offered by machine learning for mining large datasets. In realistic laboratory environments, the success of algorithmic approaches will be contingent on robust and computationally efficient algorithmic optimisation procedures. The pursuit of these opportunities is the subject of ongoing research.


\section{Acknowledgments}
 The LSF filter is written by V. Frey and S. Mavadia \cite{mavadia2017}. The GPR framework is implemented and optimised using standard protocols in GPy \cite{gpy2014}. Authors thank C. Grenade, K. Das, V. Frey, S. Mavadia, H. Ball, C. Ferrie and T. Scholten for useful comments. 
 
